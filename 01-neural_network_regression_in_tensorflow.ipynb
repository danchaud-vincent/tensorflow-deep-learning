{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Neural Network Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Content of this notebook :**\n",
    "- Architecture of a regression model\n",
    "- Input shapes and output shapes\n",
    "    - `X`: features/data (inputs)\n",
    "    - `y`: labels (outputs)\n",
    "- Creating custom data to view and fit\n",
    "- Steps in modelling\n",
    "    - Creating a model\n",
    "    - Compiling a model\n",
    "        - Defining a loss function\n",
    "        - Setting up an optimizer\n",
    "        - Creating evaluation metrics\n",
    "    - Fitting a model (getting it to find patterns in our data)\n",
    "- Evaluating a model\n",
    "    - Visualizing the model \n",
    "    - Looking at training curves\n",
    "    - Compare predictions to ground truth\n",
    "- Saving a model\n",
    "- Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorfow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import numpy \n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many definitions for a regression problem but in our case, we're going to simplify it to be: predicting a number.\n",
    "\n",
    "For example, we might want to:\n",
    "- Predict the selling price of houses given information about them (such as number of rooms, size, number of bathrooms...).\n",
    "- Predict coordinates of a bounding box of an item in an image.\n",
    "- Predict the cost of medical insurance for an individual given their demographics (age, sex, gender, race)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical architecture of a regression neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word typical is on purpose. Why?\n",
    "\n",
    "Because there are many different ways to write neural networks. But the following is a generic setup for ingesting a collection of numbers, finding patterns in them and then outputing some kind of target number.\n",
    "\n",
    "| **Hyperparameter** | **Typical Value** |\n",
    "| --- | --- |\n",
    "| Input layer shape | Same shape as number of features (e.g. 3 for #bedrooms, #bathrooms, #car spaces in housing price prediction) |\n",
    "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |\n",
    "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
    "| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |\n",
    "| Hidden activation | Usually ReLU (rectified linear unit) |\n",
    "| Output activation | None, ReLU, logistic/tanh |\n",
    "| Loss function | MSE (mean squar error) or MAE (mean absolute error) ... |\n",
    "| Optimizer | SGD (stochastic gradient descent), Adam ... |\n",
    "\n",
    "***Table 1:*** *Typical architecture of a regression network.* ***Source:*** *Adapted from page 293 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aurélien Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*\n",
    "\n",
    "> **Note**: A **hyperparamter** in machine learning is something a data analyst or developer can set themselves, where as a **parameter** usually describes something a model learns on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data to view and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're working on a **regression problem** (predicting a number) let's create some linear data to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x165461cc280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any modelling, can we calculate the pattern between `X` and `y` ?\n",
    "\n",
    "For example, based on this data what the `y` value if `X` is 17.0? Or if `X` is -10.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression input shapes and output shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important concepts when working with neural networks are the input and output shapes.\n",
    "\n",
    "- The **input shape** is the shape of your data that goes into the model.\n",
    "- The **output shape** is the shape of your data we want to come out of the model.\n",
    "\n",
    "Neural networks accept numbers and output numbers. These numbers are typically represented as tensors (or arrays).\n",
    "\n",
    "Before we created data using NumPy arrays, but we could do the same with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_info = tf.constant([\"bedroom\",\"bathroom\",\"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x16546983d90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features (using tensors)\n",
    "X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels (using tensors)\n",
    "y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here will be to use `X` to predict `y`. So our **input** will be `X` and our **output** will be `y`.\n",
    "\n",
    "What is the shape of our input and output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a single example of X\n",
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=-7.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single example of our dataset\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is only 2 small lists of numbers, so each example is a scalar with a rank 0.\n",
    "\n",
    "In our case, we're trying to build a model to predict the pattern between `X[0]` equalling `-7.0` and `y[0]` equalling `-3.0`. We are trying to use one X value to predict one y value.\n",
    "\n",
    "<center><img src=\"images/01-input-and-output-shapes-housing-prices.png\" width=600px></center>\n",
    "\n",
    "*If you were working on building a machine learning algorithm for predicting housing prices, your inputs may be number of bedrooms, number of bathrooms and number of garages, giving you an input shape of 3 (3 different features). And since you're trying to predict the price of the house, your output shape would be 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n",
    "\n",
    "1. **Creating a model** - piece together the layers of a neural network yourself (using the Functional or Sequential API) or import a previously built model (known as transfer learninng).\n",
    "2. **Compiling a model** - defining how a model performance should be measured (loss/metrics) as well as defining how it should improve (optimizer).\n",
    "3 **Fitting a model** - letting the model try to find patterns in the data (how does `X` get to `y`).\n",
    "\n",
    "Let's see these in action using the `Keras Sequential API` to build a model for our regression data.\n",
    "\n",
    "> **Note**: if you're using TensorFlow 2.7.0+, the `fit()` function no longer upscales input data to go from `(batch_size,)` to `(batch_size,1)`. To fix this, we need to expand the dimension of input data using `tf.expand_dims(input_data,axis=-1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1654cc54df0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae -> Mean Absolute error\n",
    "              optimizer = tf.keras.optimizers.SGD(), # SQG is short for stochastic gradient descent\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1654e00bd30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other way to write the model\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using the model\n",
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't go very well for the prediction. IT should've output something close to 27.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we improve the model?\n",
    "\n",
    "To improve the model, we alter almost every part of the 3 steps we went through before.\n",
    "\n",
    "1. **Creating a model** - Here you might want to add more layers, increase the number of hidden units within each layer, change the activation functions of each layer.\n",
    "2. **Compiling a model** - you might want te choose optimization function or perhaps change the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - perhaps you could fit a model for more **epochs** or on more data.\n",
    "\n",
    "<center><img src=\"images/02-improving-a-model-from-model-perspective.png\" width=650px></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9748 - mae: 10.9748\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8423 - mae: 10.8423\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7098 - mae: 10.7098\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5773 - mae: 10.5773\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4448 - mae: 10.4448\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3123 - mae: 10.3123\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1798 - mae: 10.1798\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0473 - mae: 10.0473\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9148 - mae: 9.9148\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7823 - mae: 9.7823\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6498 - mae: 9.6498\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5173 - mae: 9.5173\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3848 - mae: 9.3848\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2523 - mae: 9.2523\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1198 - mae: 9.1198\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9873 - mae: 8.9873\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8548 - mae: 8.8548\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7223 - mae: 8.7223\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5898 - mae: 8.5898\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4573 - mae: 8.4573\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3248 - mae: 8.3248\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1923 - mae: 8.1923\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0598 - mae: 8.0598\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9273 - mae: 7.9273\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7948 - mae: 7.7948\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6623 - mae: 7.6623\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5298 - mae: 7.5298\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3973 - mae: 7.3973\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2648 - mae: 7.2648\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1963 - mae: 7.1963\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1738 - mae: 7.1738\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1063 - mae: 7.1063\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8869 - mae: 6.8869\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8813 - mae: 6.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1654e011130>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more epochs to our model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice the loss value decrease from before (and keep decreasing as the number of epochs get higher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.158512]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a new prediction with the new model\n",
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is much better. Now we need to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice : Try other changes to improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 12.3203 - mae: 12.3203\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1611 - mae: 11.1611\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9503 - mae: 9.9503\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6481 - mae: 8.6481\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2624 - mae: 7.2624\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2141 - mae: 7.2141\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1656 - mae: 7.1656\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1167 - mae: 7.1167\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0674 - mae: 7.0674\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0178 - mae: 7.0178\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9677 - mae: 6.9677\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9170 - mae: 6.9170\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8658 - mae: 6.8658\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8139 - mae: 6.8139\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7614 - mae: 6.7614\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7081 - mae: 6.7081\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6540 - mae: 6.6540\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5990 - mae: 6.5990\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5431 - mae: 6.5431\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5327 - mae: 6.5327\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0231 - mae: 7.0231\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7256 - mae: 6.7256\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5607 - mae: 6.5607\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9293 - mae: 6.9293\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2442 - mae: 6.2442\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1835 - mae: 6.1835\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1213 - mae: 6.1213\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0576 - mae: 6.0576\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9924 - mae: 5.9924\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9254 - mae: 5.9254\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9162 - mae: 5.9162\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4863 - mae: 6.4863\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1402 - mae: 6.1402\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9392 - mae: 5.9392\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4679 - mae: 6.4679\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4358 - mae: 6.4358\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7940 - mae: 5.7940\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.8658 - mae: 5.8658\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0780 - mae: 6.0780\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3482 - mae: 6.3482\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4601 - mae: 5.4601\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7510 - mae: 5.7510\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7252 - mae: 5.7252\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2233 - mae: 6.2233\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1320 - mae: 5.1320\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5940 - mae: 5.5940\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4024 - mae: 5.4024\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0601 - mae: 6.0601\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8035 - mae: 4.8035\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3931 - mae: 5.3931\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1029 - mae: 5.1029\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.8570 - mae: 5.8570\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4676 - mae: 4.4676\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1457 - mae: 5.1457\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8200 - mae: 4.8200\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6116 - mae: 5.6116\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1171 - mae: 4.1171\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8485 - mae: 4.8485\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5472 - mae: 4.5472\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3208 - mae: 5.3208\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7438 - mae: 3.7438\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4968 - mae: 4.4968\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2773 - mae: 4.2773\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9805 - mae: 4.9805\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3383 - mae: 3.3383\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0848 - mae: 4.0848\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0027 - mae: 4.0027\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5859 - mae: 4.5859\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8920 - mae: 2.8920\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0751 - mae: 5.0751\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3982 - mae: 2.3982\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6689 - mae: 5.6689\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0217 - mae: 4.0217\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5207 - mae: 2.5207\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8024 - mae: 4.8024\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9651 - mae: 2.9651\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6898 - mae: 5.6898\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8426 - mae: 2.8426\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5565 - mae: 5.5565\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7261 - mae: 2.7261\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4362 - mae: 5.4362\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6366 - mae: 2.6366\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0203 - mae: 4.0203\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1705 - mae: 3.1705\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7997 - mae: 4.7997\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0423 - mae: 3.0423\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7211 - mae: 4.7211\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0346 - mae: 2.0346\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1576 - mae: 4.1576\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5082 - mae: 3.5082\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1100 - mae: 4.1100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4289 - mae: 2.4289\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0008 - mae: 5.0008\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3409 - mae: 2.3409\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9120 - mae: 4.9120\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2572 - mae: 2.2572\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8301 - mae: 4.8301\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1776 - mae: 2.1776\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7543 - mae: 4.7543\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1020 - mae: 2.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1654ced4370>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more layers to the model and see if the prediction is improved\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50),\n",
    "    tf.keras.layers.Dense(25),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer= tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.918866]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0548 - mae: 11.0548\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6048 - mae: 10.6048\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1548 - mae: 10.1548\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7048 - mae: 9.7048\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2548 - mae: 9.2548\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8048 - mae: 8.8048\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3548 - mae: 8.3548\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9048 - mae: 7.9048\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4548 - mae: 7.4548\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0048 - mae: 7.0048\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6750 - mae: 6.6750\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6013 - mae: 6.6013\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6652 - mae: 6.6652\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7835 - mae: 6.7835\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8536 - mae: 6.8536\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8819 - mae: 6.8819\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8739 - mae: 6.8739\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8341 - mae: 6.8341\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7664 - mae: 6.7664\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6741 - mae: 6.6741\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5602 - mae: 6.5602\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4269 - mae: 6.4269\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2766 - mae: 6.2766\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1110 - mae: 6.1110\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9319 - mae: 5.9319\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7406 - mae: 5.7406\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6637 - mae: 5.6637\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6047 - mae: 5.6047\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5441 - mae: 5.5441\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5875 - mae: 5.5875\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5963 - mae: 5.5963\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5469 - mae: 5.5469\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4464 - mae: 5.4464\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3007 - mae: 5.3007\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1335 - mae: 5.1335\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.0600 - mae: 5.0600\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9867 - mae: 4.9867\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9135 - mae: 4.9135\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8405 - mae: 4.8405\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7975 - mae: 4.7975\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7608 - mae: 4.7608\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6963 - mae: 4.6963\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6069 - mae: 4.6069\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4952 - mae: 4.4952\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4298 - mae: 4.4298\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3643 - mae: 4.3643\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2979 - mae: 4.2979\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2308 - mae: 4.2308\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1630 - mae: 4.1630\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0946 - mae: 4.0946\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0652 - mae: 4.0652\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9794 - mae: 3.9794\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8806 - mae: 3.8806\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8071 - mae: 3.8071\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7336 - mae: 3.7336\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6601 - mae: 3.6601\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5867 - mae: 3.5867\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5133 - mae: 3.5133\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4709 - mae: 3.4709\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4081 - mae: 3.4081\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3176 - mae: 3.3176\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2315 - mae: 3.2315\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.1632 - mae: 3.1632\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0943 - mae: 3.0943\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0249 - mae: 3.0249\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9549 - mae: 2.9549\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8846 - mae: 2.8846\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8139 - mae: 2.8139\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7546 - mae: 2.7546\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6693 - mae: 2.6693\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5958 - mae: 2.5958\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5222 - mae: 2.5222\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4486 - mae: 2.4486\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3750 - mae: 2.3750\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3013 - mae: 2.3013\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2415 - mae: 2.2415\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1651 - mae: 2.1651\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0865 - mae: 2.0865\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0164 - mae: 2.0164\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9459 - mae: 1.9459\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8750 - mae: 1.8750\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8037 - mae: 1.8037\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7388 - mae: 1.7388\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6581 - mae: 1.6581\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5841 - mae: 1.5841\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5100 - mae: 1.5100\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4441 - mae: 1.4441\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3693 - mae: 1.3693\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2943 - mae: 1.2943\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2239 - mae: 1.2239\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1547 - mae: 1.1547\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0798 - mae: 1.0798\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0064 - mae: 1.0064\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9329 - mae: 0.9329\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8770 - mae: 0.8770\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7953 - mae: 0.7953\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7183 - mae: 0.7183\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6788 - mae: 0.6788\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5930 - mae: 0.5930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1654e059190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the optimizer \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.401552]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 13.9468 - mae: 13.9468\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.2859 - mae: 13.2859\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.6279 - mae: 12.6279\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.9702 - mae: 11.9702\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3044 - mae: 11.3044\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6244 - mae: 10.6244\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9248 - mae: 9.9248\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1949 - mae: 9.1949\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4303 - mae: 8.4303\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6245 - mae: 7.6245\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7723 - mae: 6.7723\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8960 - mae: 5.8960\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9754 - mae: 4.9754\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1323 - mae: 4.1323\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0312 - mae: 4.0312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9276 - mae: 3.9276\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9605 - mae: 3.9605\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9073 - mae: 3.9073\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9714 - mae: 3.9714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8999 - mae: 3.8999\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9595 - mae: 3.9595\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9079 - mae: 3.9079\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9333 - mae: 3.9333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9160 - mae: 3.9160\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9096 - mae: 3.9096\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9309 - mae: 3.9309\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8864 - mae: 3.8864\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9391 - mae: 3.9391\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8681 - mae: 3.8681\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9381 - mae: 3.9381\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8763 - mae: 3.8763\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9117 - mae: 3.9117\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8854 - mae: 3.8854\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8910 - mae: 3.8910\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8996 - mae: 3.8996\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8641 - mae: 3.8641\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9080 - mae: 3.9080\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8374 - mae: 3.8374\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9154 - mae: 3.9154\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8459 - mae: 3.8459\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8888 - mae: 3.8888\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8594 - mae: 3.8594\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8678 - mae: 3.8678\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8695 - mae: 3.8695\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8407 - mae: 3.8407\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8782 - mae: 3.8782\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8134 - mae: 3.8134\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8870 - mae: 3.8870\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8165 - mae: 3.8165\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8678 - mae: 3.8678\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8318 - mae: 3.8318\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8433 - mae: 3.8433\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8405 - mae: 3.8405\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8159 - mae: 3.8159\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8494 - mae: 3.8494\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7884 - mae: 3.7884\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8585 - mae: 3.8585\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7889 - mae: 3.7889\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8451 - mae: 3.8451\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8037 - mae: 3.8037\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8175 - mae: 3.8175\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8126 - mae: 3.8126\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7899 - mae: 3.7899\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8218 - mae: 3.8218\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7622 - mae: 3.7622\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8311 - mae: 3.8311\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7651 - mae: 3.7651\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8185 - mae: 3.8185\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7766 - mae: 3.7766\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7906 - mae: 3.7906\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7858 - mae: 3.7858\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7627 - mae: 3.7627\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7952 - mae: 3.7952\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7347 - mae: 3.7347\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8055 - mae: 3.8055\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7414 - mae: 3.7414\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7906 - mae: 3.7906\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7506 - mae: 3.7506\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7624 - mae: 3.7624\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7599 - mae: 3.7599\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7342 - mae: 3.7342\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7696 - mae: 3.7696\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7059 - mae: 3.7059\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7833 - mae: 3.7833\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7162 - mae: 3.7162\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7614 - mae: 3.7614\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7255 - mae: 3.7255\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7328 - mae: 3.7328\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7351 - mae: 3.7351\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7044 - mae: 3.7044\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6776 - mae: 3.6776\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7594 - mae: 3.7594\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6919 - mae: 3.6919\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7307 - mae: 3.7307\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7015 - mae: 3.7015\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7019 - mae: 3.7019\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7114 - mae: 3.7114\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6731 - mae: 3.6731\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7214 - mae: 3.7214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1654f265b50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see another change to improve our model\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# fit\n",
    "model.fit(tf.expand_dims(X,axis=-1),y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001654E1C7E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.941305]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see making some changes on our model can improve the result. Adding more layers or training our model on more epochs improved the result on the loss of our model. We can see that changing also the optimizer by using Adam improved a lot the model with a loss close to 0.6 and a prediction close to 27.\n",
    "\n",
    "However we can see in the examples that even if the loss is improved in some models, the result is still not close to 27. It means that maybe our model is overfitting on our training data. It is learning the patterns between X and y far too well. So when it sees a new x, it's just relating it back to what is knows and the error that it's producing during training is not a really valid representation.\n",
    "\n",
    "Now we have trained the model, we need to evaluate it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to evaluation, we'll want to remember the words: \"visualize, visualize, visualize.\" \n",
    "\n",
    "It's a good idea to visualize:\n",
    "- **The data** - what data are you looking with? What does it look like?\n",
    "- **The model itself** - what does the architecture look like? What are different shapes?\n",
    "- **The training of a model** - how does a model perform while it learns?\n",
    "- **The predictions of a model** - how do the predictions of a model line up against the ground truth (the original labels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100,100,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "y = X + 10\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training/test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the other most important steps in machine learning project is creating a training and test set (and when required, a validation set).\n",
    "\n",
    "Each set serves a specific purposes:\n",
    "- **Training set** - the model learns from this data, which is typically 70-80% of the total data available.\n",
    "- **Validation set** - the model gets tuned on this ddata, which is typically 10-15% of the total data available.\n",
    "- **Test set** - the model gets evaluated on this data to test what it has learned, it's typically 10-15% of the total data available.\n",
    "\n",
    "For now, we'll just use a training and a test set, this means we'll have a dataset for our model to learn as well as be evaluated on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many samples we have\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "# train set\n",
    "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
    "y_train = y[:40]\n",
    "\n",
    "# test set\n",
    "X_test = X[40:] # the last 10 are testing samples (20% of the data)\n",
    "y_test = y[40:]\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "# plot training data in blue\n",
    "plt.scatter(X_train,y_train,c=\"b\",label=\"Training data\")\n",
    "\n",
    "# plot testing data in green\n",
    "plt.scatter(X_test,y_test, c=\"g\", label = \"Testing data\")\n",
    "\n",
    "# show legend and the fig\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-f53f18c8aa15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[0;32m   2773\u001b[0m     \"\"\"\n\u001b[0;32m   2774\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2775\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m   2776\u001b[0m           \u001b[1;34m'This model has not yet been built. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2777\u001b[0m           \u001b[1;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above errors because we haven't fit or built our model. We also haven't told it what input shape it should be expecting.\n",
    "\n",
    "We can let our model know the input shape of our data using the `input_shape` parameter to the first layer (usually if `input_shape` isn't defined, Keras tries to figure it out automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape of the input\n",
    "X[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds  automatically by defining the input_shape arguments\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1,input_shape=[1])\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `summary()` on our model shows us the layers it contains, the output shape and the number of parameters.\n",
    "- **Total params** - total number of parameters in the model\n",
    "- **Trainable params** - these are the paramters (patterns) the model can update as it trains.\n",
    "- **Non-trainable parameters** - these parameters aren't updated during training (this is typical when you bring in the already patterns from other models during transfer learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercice:** Try playing around with the number of hidden units in the Dense layer (e.g. Dense(2), Dense(3)). How does this change the Total/Trainable params? Investigate what's causing the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10)                20        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Exercice\n",
    "\n",
    "# model 1 \n",
    "model_Exercice1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10,input_shape=[1],name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1,name=\"output_layer\")\n",
    "],name=\"model_1\")\n",
    "\n",
    "model_Exercice1.compile(loss=tf.keras.losses.mae,\n",
    "                        optimizer = tf.keras.optimizers.SGD(),\n",
    "                        metrics=[\"mae\"])\n",
    "\n",
    "model_Exercice1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 4)                 8         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Exercice\n",
    "\n",
    "# model 2\n",
    "model_Exercice2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4,input_shape=[1]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_Exercice2.compile(loss=tf.keras.losses.mae,\n",
    "                        optimizer = tf.keras.optimizers.SGD(),\n",
    "                        metrics=[\"mae\"])\n",
    "\n",
    "model_Exercice2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit our model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x165512c7f10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train,y_train,epochs=100, verbose=1) # verbose controls how much gets output (0 no outputs, 1 default output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydot\n",
    "#pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(model=model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize predictions, it's always a good idea to plot them against the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53.57109 ],\n",
       "       [57.05633 ],\n",
       "       [60.541573],\n",
       "       [64.02681 ],\n",
       "       [67.512054],\n",
       "       [70.99729 ],\n",
       "       [74.48254 ],\n",
       "       [77.96777 ],\n",
       "       [81.45301 ],\n",
       "       [84.938255]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make som predictions\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(X_train,y_train,X_test,y_test,predictions):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and the predictions\n",
    "\n",
    "    Inputs:\n",
    "    - X_train : training data features\n",
    "    - y_train : training data labels\n",
    "    - X_test : test data features\n",
    "    - y_test : test data labels\n",
    "    - predictions : predictions \n",
    "    \"\"\"\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(10,7))\n",
    "\n",
    "    # Plot the training data\n",
    "    plt.scatter(X_train,y_train,c=\"b\",label=\"Training data\")\n",
    "\n",
    "    # Plot the testing data\n",
    "    plt.scatter(X_test,y_test,c=\"g\",label=\"Testing data\")\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.scatter(X_test, predictions, c=\"r\", label=\"Predictions\")\n",
    "\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(X_train,y_train,X_test,y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
