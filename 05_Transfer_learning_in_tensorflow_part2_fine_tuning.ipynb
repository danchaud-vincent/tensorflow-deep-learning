{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMxHB8s8KqJfAN09DrsDQd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danchaud-vincent/tensorflow-deep-learning/blob/main/05_Transfer_learning_in_tensorflow_part2_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 05. Transfer Learning with TensorFlow Part 2: Fine-tuning"
      ],
      "metadata": {
        "id": "oKfQArbiYHeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food Vision project than building our own models (even with less data).\n",
        "\n",
        "Now we're going to cover another type of transfer learning: fine-tuning.\n",
        "\n",
        "In **fine-tuning transfer learning** the pre-trained model weights from another model are unfrozen and tweaked during to better suit your own data.\n",
        "\n",
        "For feature extraction transfer learning, you may only train the top 1-3 layers of a pre-trained model with your own data, in fine-tuning transfer learning, you might train 1-3+ of pre-trained model.\n",
        "\n",
        "![](https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/images/05-transfer-learning-feature-extraction-vs-fine-tuning.png)"
      ],
      "metadata": {
        "id": "ezI2AdvMYFI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What we're going to cover\n",
        "\n",
        "We're going to go through the follow with TensorFlow:\n",
        "- Introduce fine-tuning, a type of transfer learning to modify a pre-trained model to be more suited to your data.\n",
        "- Using the Keras Functional API (a different way to build models in Keras)\n",
        "- Using a smaller dataset to experiment faster (e.g. 1-10% of training samples of 10 classes of food)\n",
        "- Data augmentation (how to make your training dataset more diverse without adding more data)\n",
        "- Running a series of modelling experiments on our Food Vision data:\n",
        "  - Model 0: a transfer learning model using Keras Functional API\n",
        "  - Model 1: a feature extraction transfer learning model on 1% of the data with data augmentation\n",
        "  - Model 2 : a feature extraction transfer learning model on 10 % of the data with data augmentation\n",
        "  - Model 3: a fine-tuned transfer learning model on 10% of the data\n",
        "  - Model 4: a fine-tuned transfer learning model on 100% of the data\n",
        "- Introduce the ModelCheckpoint callback to save intermediate training results\n",
        "- Compare model experiments results using TensorBoard"
      ],
      "metadata": {
        "id": "dsqKUaq6jTdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a GPU?\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQaOixQWkW0Y",
        "outputId": "e9206cad-ba07-4ef3-df88-783832b018f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct  8 13:36:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions\n",
        "\n",
        "Throughout your machine learning experiments, you'll likely come accross snippets of code you want to use over and over again.\n",
        "\n",
        "For example, a plotting function which plots a model's `history` object (see `plot_loss_curves()` below).\n",
        "\n",
        "You could recreate these functions over and over again. But as you might have guessed, rewritting the same functions becomes tedious.\n",
        "\n",
        "One of the solutions is to store them in a helper functions script such as `helper_functions.py`. And then import the necessary functionality when you need it.\n",
        "\n",
        "\n",
        "Let's see what this looks like."
      ],
      "metadata": {
        "id": "M0HG8i19jTUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from course GitHub\n",
        "!wget https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/utils/helper_functions.py "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BmHk2qUtmve",
        "outputId": "306a5004-1d32-4f47-dec0-0750c93fda2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-08 13:36:44--  https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/utils/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2631 (2.6K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]   2.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-08 13:36:45 (52.4 MB/s) - ‘helper_functions.py’ saved [2631/2631]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import Helper functions we're going to use\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, walk_through_dir, unzip_data"
      ],
      "metadata": {
        "id": "gQnBafFPtwpi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1O Food Classes: Working with less data"
      ],
      "metadata": {
        "id": "oJuX3A_EjhCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw in the previous notebook that we could get great results with only 10% of the training data using transfer learning with TensorFlow Hub.\n",
        "\n",
        "In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use the in-built pretrained models within the `tf.keras.applications` module as well as how to fine-tune them to our own custom dataset.\n",
        "\n",
        "We'll also practice using a new but similar dataloader function to what we've used before, `image_dataset_from_directory()` which is part of the `tf.keras.preprocessing` module.\n",
        "\n",
        "Finally, we'll also be practicing using the [`Keras Functional API`](https://keras.io/guides/functional_api/) for building deep learning models. The Functional API is a more flexible way to create models than the tf.keras.Sequential API."
      ],
      "metadata": {
        "id": "Vd5Z-IGcjkt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of the data of the 10 classes\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "id": "BiVTo1O0t8ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8210df-ace8-4f85-c12a-832758257283"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-08 13:36:47--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 173.194.210.128, 173.194.211.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  46.8MB/s    in 3.4s    \n",
            "\n",
            "2022-10-08 13:36:51 (46.8 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the data\n",
        "unzip_data(\"/content/10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "aEqo5SJFlbQV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# walkthrough the directories\n",
        "walk_through_dir(\"/content/10_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "-L8KGh_nllqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394595c5-6229-48b9-fcce-2d901eb25a25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/10_food_classes_10_percent: There are 2 directories and 0 files\n",
            "/content/10_food_classes_10_percent/test: There are 10 directories and 0 files\n",
            "/content/10_food_classes_10_percent/test/chicken_wings: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/steak: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/hamburger: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/fried_rice: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/ice_cream: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/chicken_curry: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/ramen: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/sushi: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/grilled_salmon: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/pizza: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/train: There are 10 directories and 0 files\n",
            "/content/10_food_classes_10_percent/train/chicken_wings: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/steak: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/hamburger: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/fried_rice: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/ice_cream: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/chicken_curry: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/ramen: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/sushi: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/grilled_salmon: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/pizza: There are 0 directories and 75 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test directories\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "id": "NTN786l7nipK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got some image data, we need a way of loading it into a TensorFlow compatible format.\n",
        "\n",
        "Previously we've used the `ImageDataGenerator` class. And while this works well and is still very commonly used, this time we're going to use the `image_data_from_directory` function.\n",
        "\n",
        "It works much the same way as `ImageDataGenerator`'s `flow_from_directory` method meaning your images need to be in the following file format:\n",
        "\n",
        "Example of file structure:\n",
        "10_food_classes_10_percent <- top level folder\n",
        "└───train <- training images \n",
        "│   │   │     \n",
        "│   └───pizza\n",
        "    \n",
        "│- - - - -  1008104.jpg'\n",
        "\n",
        "│- - - - -  1638227.jpg\n",
        " \n",
        "│- - - - -  ...      \n",
        "│   └───steak\n",
        "\n",
        "│- - - - -  1000205.jpg\n",
        "\n",
        "│- - - - -  1647351.jpg\n",
        "\n",
        "│- - - - -   ...\n",
        "      \n",
        "└───test <- testing images\n",
        "\n",
        "│   └───pizza\n",
        "\n",
        "│- - - - -  1001116.jpg\n",
        "\n",
        "│- - - - -  1507019.jpg\n",
        "\n",
        "│- - - - -  ...      \n",
        "\n",
        "│   └───steak\n",
        "\n",
        "│- - - - -  100274.jpg\n",
        "\n",
        "│- - - - -  1653815.jpg\n",
        "\n",
        "│- - - - -  ...   \n",
        "\n",
        "One of the main benefits of using `tf.keras.preprocessing.image_dataset_from_directory()` rather than `ImageDataGenerator` is that it creates a `tf.data.Dataset` object rather than a generator. The main advantage of this is the `tf.data.Dataset` API is much more efficient (faster) than the `ImageDataGenerator` API which is paramount for larger datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "z-DPeXrpoNtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data inputs\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\", # what type are the labels?\n",
        "                                                                            batch_size=BATCH_SIZE) # batch_size is 32 by default, this is generally a good number\n",
        "\n",
        "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           label_mode=\"categorical\",\n",
        "                                                                           batch_size=BATCH_SIZE)                                                                         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LjvGJP3oLGu",
        "outputId": "606820e7-ba18-41c6-e9d2-52e6fa5f502b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like our dataloaders have found the correct number of images for each dataset.\n",
        "\n",
        "For now, the main parameters we're concerned about in the `image_dataset_from_directory()` function are:\n",
        "- `directory` - the filepath of the target directory we're loading images in from.\n",
        "- `image_size` - the target size of the images we're going to load in (height, width).\n",
        "- `batch_size` - the batch size of the images we're going to load in. For example if the batch_size is 32 (the default), batches of 32 images and labels at a time will be passed to the model."
      ],
      "metadata": {
        "id": "HVm-d7ymsWqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the training data datatype\n",
        "train_data_10_percent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAyUIAGusNfR",
        "outputId": "8044badf-8240-41fa-94c0-cfe27b22a314"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above output:\n",
        "- `(None, 224, 224, 3)` refers to the tensor shape of our images where `None` is the batch size, `224` is the height (and width) and `3` is the color channel (red, green blue).\n",
        "- `(None, 10)` refers to the tensor shape of the labels where `None` is the batch size and `10` is the number of possible labels (the 10 different food classes).\n",
        "- Both image tensors and labels are of the datatype `tf.float32`.\n",
        "\n",
        "The `batch_size` is `None` due to it only being used during model training. You can think `None` as a placeholder waiting to be filled with the `batch_size` parameter from `image_dataset_from_directory()`.\n",
        "\n",
        "Another benefit of using `tf.data.Dataset` API are the associated methods which come with it.\n",
        "\n",
        "For example, if we want to find the name of the classes we were working with, we could use the `class_names` attribute."
      ],
      "metadata": {
        "id": "uEEfb85wvp1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the class names of our dataset\n",
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcbWYoTHvhka",
        "outputId": "38756213-39ce-4eb3-d000-26c90837cb9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See an example of batch of data\n",
        "train_data_10_percent.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrL4nUlOxFJ1",
        "outputId": "8b2d9717-3595-4a9c-be5f-c0a8564bbea1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images)\n",
        "  print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbx2VKNXxMQ3",
        "outputId": "6e35b0b8-07a5-47c2-a68f-b8bfb64165d1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[9.58418350e+01 7.88418350e+01 6.88418350e+01]\n",
            "   [1.01811226e+02 8.48112259e+01 7.48112259e+01]\n",
            "   [1.02071426e+02 8.50714264e+01 7.70714264e+01]\n",
            "   ...\n",
            "   [3.61684380e+01 3.77399101e+01 3.69541740e+01]\n",
            "   [3.75153999e+01 3.95153999e+01 3.85153999e+01]\n",
            "   [1.01710815e+02 1.03710815e+02 1.02710815e+02]]\n",
            "\n",
            "  [[9.97857132e+01 8.27857132e+01 7.27857132e+01]\n",
            "   [1.00785713e+02 8.37857132e+01 7.37857132e+01]\n",
            "   [1.00372452e+02 8.29438782e+01 7.35867386e+01]\n",
            "   ...\n",
            "   [3.25102119e+01 3.45102119e+01 3.35102119e+01]\n",
            "   [4.00867767e+01 4.20867767e+01 4.10867767e+01]\n",
            "   [6.01892624e+01 6.21892624e+01 6.11892624e+01]]\n",
            "\n",
            "  [[9.75051041e+01 7.97193909e+01 6.97193909e+01]\n",
            "   [9.89285736e+01 8.11428604e+01 7.11428604e+01]\n",
            "   [1.03214287e+02 8.53367386e+01 7.54744949e+01]\n",
            "   ...\n",
            "   [4.18367882e+01 4.38367882e+01 4.28367882e+01]\n",
            "   [3.60715065e+01 3.80715065e+01 3.70715065e+01]\n",
            "   [5.86585350e+01 6.06585350e+01 5.96585350e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[5.39898071e+01 2.66326904e+01 2.49898071e+01]\n",
            "   [5.25867615e+01 2.68010559e+01 2.51581726e+01]\n",
            "   [5.36888123e+01 2.79031067e+01 2.62602234e+01]\n",
            "   ...\n",
            "   [1.83570862e+01 1.09999695e+01 7.99996948e+00]\n",
            "   [1.64999695e+01 1.18724566e+01 8.01530933e+00]\n",
            "   [1.42244329e+01 1.16530218e+01 6.86731577e+00]]\n",
            "\n",
            "  [[5.28111839e+01 2.78111820e+01 2.38111820e+01]\n",
            "   [5.32091484e+01 2.82091503e+01 2.42091503e+01]\n",
            "   [5.51428223e+01 3.01428223e+01 2.61428223e+01]\n",
            "   ...\n",
            "   [1.61428528e+01 1.20714417e+01 9.07144165e+00]\n",
            "   [1.59898272e+01 1.47908993e+01 1.08572083e+01]\n",
            "   [1.83112736e+01 1.79746151e+01 1.36429443e+01]]\n",
            "\n",
            "  [[4.86428642e+01 2.36428661e+01 1.96428661e+01]\n",
            "   [4.79285812e+01 2.29285793e+01 1.89285793e+01]\n",
            "   [4.70000153e+01 2.22143021e+01 1.82143021e+01]\n",
            "   ...\n",
            "   [1.64183025e+01 1.39336405e+01 1.24285278e+01]\n",
            "   [1.48571777e+01 1.45255461e+01 1.25255461e+01]\n",
            "   [1.71734886e+01 1.87143250e+01 1.59439068e+01]]]\n",
            "\n",
            "\n",
            " [[[7.25969391e+01 3.95969391e+01 3.20255089e+01]\n",
            "   [7.76173477e+01 4.42806129e+01 3.20918388e+01]\n",
            "   [7.37857132e+01 5.05561256e+01 3.80714340e+01]\n",
            "   ...\n",
            "   [1.00662909e+01 1.70662899e+01 9.28055477e+00]\n",
            "   [1.00255146e+01 1.60255146e+01 6.02551508e+00]\n",
            "   [1.23265553e+01 1.53265553e+01 6.32655525e+00]]\n",
            "\n",
            "  [[7.24489746e+01 4.32857170e+01 2.95255108e+01]\n",
            "   [7.43418350e+01 4.13367310e+01 2.46275482e+01]\n",
            "   [8.01734695e+01 5.27908173e+01 3.95612259e+01]\n",
            "   ...\n",
            "   [1.45306320e+01 1.95306320e+01 1.27448959e+01]\n",
            "   [1.27244663e+01 1.77244663e+01 1.07244663e+01]\n",
            "   [1.05458813e+01 1.35458813e+01 4.54588127e+00]]\n",
            "\n",
            "  [[7.51326523e+01 4.71326523e+01 2.59183655e+01]\n",
            "   [7.63673477e+01 4.43673477e+01 2.33367348e+01]\n",
            "   [7.47602005e+01 4.17602043e+01 2.80459194e+01]\n",
            "   ...\n",
            "   [1.15460005e+01 1.41174288e+01 7.33171463e+00]\n",
            "   [1.23316154e+01 1.53316154e+01 8.33161545e+00]\n",
            "   [1.14184227e+01 1.44184227e+01 7.41842270e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.40780670e+02 1.29423462e+02 1.15770432e+02]\n",
            "   [1.42000000e+02 1.33000000e+02 1.16142853e+02]\n",
            "   [1.39000015e+02 1.32091843e+02 1.13663300e+02]\n",
            "   ...\n",
            "   [1.41194077e+02 1.33097031e+02 1.25668510e+02]\n",
            "   [1.46229568e+02 1.35658096e+02 1.29443832e+02]\n",
            "   [1.37642822e+02 1.26642822e+02 1.20642822e+02]]\n",
            "\n",
            "  [[1.36877533e+02 1.23071388e+02 1.14877525e+02]\n",
            "   [1.39923462e+02 1.30499954e+02 1.15928558e+02]\n",
            "   [1.42357132e+02 1.33571411e+02 1.16142845e+02]\n",
            "   ...\n",
            "   [1.39596863e+02 1.29025391e+02 1.22811134e+02]\n",
            "   [1.38061234e+02 1.25061234e+02 1.19061234e+02]\n",
            "   [1.39306229e+02 1.26306236e+02 1.20306236e+02]]\n",
            "\n",
            "  [[1.39015472e+02 1.22484810e+02 1.16556236e+02]\n",
            "   [1.40000107e+02 1.27168404e+02 1.15765381e+02]\n",
            "   [1.43066360e+02 1.31846954e+02 1.15357178e+02]\n",
            "   ...\n",
            "   [1.34928467e+02 1.23928467e+02 1.17928467e+02]\n",
            "   [1.38811096e+02 1.25811104e+02 1.19811104e+02]\n",
            "   [1.38484756e+02 1.23484756e+02 1.18484756e+02]]]\n",
            "\n",
            "\n",
            " [[[4.96581650e+01 3.43010216e+01 1.63724499e+01]\n",
            "   [5.24897957e+01 3.84183693e+01 1.17040806e+01]\n",
            "   [5.16428566e+01 4.08571434e+01 1.18826523e+01]\n",
            "   ...\n",
            "   [1.96142883e+02 1.44142883e+02 9.41428757e+01]\n",
            "   [1.93285706e+02 1.41285706e+02 9.12856979e+01]\n",
            "   [1.93357147e+02 1.41357147e+02 9.13571396e+01]]\n",
            "\n",
            "  [[5.46428566e+01 3.92857132e+01 2.13571396e+01]\n",
            "   [5.31683655e+01 3.90969353e+01 1.32448969e+01]\n",
            "   [6.45867310e+01 5.34030609e+01 2.62448959e+01]\n",
            "   ...\n",
            "   [1.95928574e+02 1.43928574e+02 9.39285736e+01]\n",
            "   [1.93923462e+02 1.41923462e+02 9.19234695e+01]\n",
            "   [1.94260239e+02 1.42260239e+02 9.22602386e+01]]\n",
            "\n",
            "  [[4.01122437e+01 2.32500019e+01 3.39795971e+00]\n",
            "   [3.99081612e+01 2.46938763e+01 1.69387686e+00]\n",
            "   [3.82091827e+01 2.36377544e+01 1.92346942e+00]\n",
            "   ...\n",
            "   [1.97403076e+02 1.45617371e+02 9.49745102e+01]\n",
            "   [1.96515289e+02 1.44729584e+02 9.40867233e+01]\n",
            "   [1.97142899e+02 1.45357178e+02 9.47143173e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.05989830e+02 8.69898300e+01 5.49898338e+01]\n",
            "   [1.05984695e+02 8.69846954e+01 5.49846954e+01]\n",
            "   [1.04525513e+02 8.55255127e+01 5.35255127e+01]\n",
            "   ...\n",
            "   [4.32243271e+01 1.88674240e+01 8.29595280e+00]\n",
            "   [5.04795685e+01 2.47958870e+01 1.78673286e+01]\n",
            "   [6.49749527e+01 2.99900665e+01 2.80564499e+01]]\n",
            "\n",
            "  [[1.07285698e+02 8.62856979e+01 5.52857018e+01]\n",
            "   [1.05928558e+02 8.69285583e+01 5.49285583e+01]\n",
            "   [1.07785713e+02 8.87857132e+01 5.67857132e+01]\n",
            "   ...\n",
            "   [4.46632156e+01 1.96376362e+01 1.21275148e+01]\n",
            "   [5.98013382e+01 2.92349110e+01 2.10971317e+01]\n",
            "   [8.07910004e+01 4.11480904e+01 3.42195015e+01]]\n",
            "\n",
            "  [[1.06658287e+02 8.56582870e+01 5.46582909e+01]\n",
            "   [1.06357285e+02 8.73572845e+01 5.53572845e+01]\n",
            "   [1.06994957e+02 8.86378174e+01 5.64235306e+01]\n",
            "   ...\n",
            "   [6.30159073e+01 3.18167572e+01 2.93780518e+01]\n",
            "   [8.15362015e+01 4.22249451e+01 3.45820007e+01]\n",
            "   [1.16551971e+02 7.91387482e+01 6.41232605e+01]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[3.05714302e+01 1.26989794e+01 4.10204077e+00]\n",
            "   [3.80255089e+01 1.81683674e+01 7.23979616e+00]\n",
            "   [4.86377563e+01 2.21479588e+01 6.85714293e+00]\n",
            "   ...\n",
            "   [1.25285713e+02 8.82857132e+01 5.92857132e+01]\n",
            "   [1.25285713e+02 8.92857132e+01 5.72857132e+01]\n",
            "   [1.25285713e+02 8.92857132e+01 5.72857132e+01]]\n",
            "\n",
            "  [[3.70714264e+01 1.48826532e+01 5.02040815e+00]\n",
            "   [4.45663261e+01 2.07193890e+01 8.80102158e+00]\n",
            "   [5.31275520e+01 2.53571434e+01 8.14285755e+00]\n",
            "   ...\n",
            "   [1.29857147e+02 9.36428833e+01 6.22856712e+01]\n",
            "   [1.29857147e+02 9.38571472e+01 6.18571434e+01]\n",
            "   [1.29857147e+02 9.38571472e+01 6.18571434e+01]]\n",
            "\n",
            "  [[4.39285698e+01 1.52193880e+01 5.13775539e+00]\n",
            "   [5.16428566e+01 2.17448997e+01 7.72959185e+00]\n",
            "   [6.03571434e+01 2.56428566e+01 8.00000000e+00]\n",
            "   ...\n",
            "   [1.36428574e+02 9.74285736e+01 6.67652740e+01]\n",
            "   [1.36428574e+02 9.74285736e+01 6.64285736e+01]\n",
            "   [1.36428574e+02 9.74285736e+01 6.64285736e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.63714355e+02 9.57143478e+01 3.31428795e+01]\n",
            "   [1.60428635e+02 9.24286346e+01 2.98571644e+01]\n",
            "   [1.60571487e+02 9.25714951e+01 3.00000229e+01]\n",
            "   ...\n",
            "   [1.69168350e+02 9.91683578e+01 2.87398262e+01]\n",
            "   [1.69214264e+02 9.92142639e+01 2.87857361e+01]\n",
            "   [1.69494919e+02 9.94949112e+01 2.90663834e+01]]\n",
            "\n",
            "  [[1.70403076e+02 1.03071442e+02 3.60663261e+01]\n",
            "   [1.69071442e+02 1.02005119e+02 3.42040939e+01]\n",
            "   [1.68270416e+02 1.01071442e+02 3.36683731e+01]\n",
            "   ...\n",
            "   [1.69857117e+02 9.98571167e+01 3.08571167e+01]\n",
            "   [1.69994904e+02 9.99948959e+01 3.09948959e+01]\n",
            "   [1.70857117e+02 1.00857117e+02 3.18571167e+01]]\n",
            "\n",
            "  [[1.69285645e+02 1.02285645e+02 3.22856445e+01]\n",
            "   [1.68311157e+02 1.01311157e+02 3.13111572e+01]\n",
            "   [1.67566284e+02 1.00566284e+02 3.05662842e+01]\n",
            "   ...\n",
            "   [1.67862259e+02 9.68622665e+01 3.08622665e+01]\n",
            "   [1.68000000e+02 9.70000000e+01 3.10000000e+01]\n",
            "   [1.68357178e+02 9.73571777e+01 3.13571777e+01]]]\n",
            "\n",
            "\n",
            " [[[1.36561218e+02 1.50132660e+02 1.72061218e+02]\n",
            "   [1.33892853e+02 1.44540817e+02 1.67443878e+02]\n",
            "   [1.39591843e+02 1.45954086e+02 1.66658157e+02]\n",
            "   ...\n",
            "   [1.74224426e+02 1.66163208e+02 1.52658157e+02]\n",
            "   [1.80117386e+02 1.72117386e+02 1.59117386e+02]\n",
            "   [1.77081573e+02 1.69081573e+02 1.56081573e+02]]\n",
            "\n",
            "  [[1.52775513e+02 1.58346939e+02 1.73918365e+02]\n",
            "   [1.62673462e+02 1.65525513e+02 1.80301025e+02]\n",
            "   [1.75010208e+02 1.76010193e+02 1.88938782e+02]\n",
            "   ...\n",
            "   [1.70617294e+02 1.62760162e+02 1.51290817e+02]\n",
            "   [1.69566345e+02 1.63510223e+02 1.51642868e+02]\n",
            "   [1.71311325e+02 1.65316437e+02 1.53408279e+02]]\n",
            "\n",
            "  [[1.88387756e+02 1.85244904e+02 1.88173462e+02]\n",
            "   [1.73198975e+02 1.68198975e+02 1.72056107e+02]\n",
            "   [1.76693878e+02 1.68505096e+02 1.73005096e+02]\n",
            "   ...\n",
            "   [1.15305283e+02 1.10876709e+02 9.96624222e+01]\n",
            "   [8.42199326e+01 7.97352676e+01 7.03219681e+01]\n",
            "   [1.53852203e+02 1.50000244e+02 1.39790970e+02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[8.89030228e+01 5.11173134e+01 4.05459023e+01]\n",
            "   [8.50970078e+01 4.88827095e+01 3.75255928e+01]\n",
            "   [7.58622589e+01 4.01224518e+01 2.87194176e+01]\n",
            "   ...\n",
            "   [4.59155664e-02 4.59155664e-02 0.00000000e+00]\n",
            "   [7.14416504e-02 7.14416504e-02 0.00000000e+00]\n",
            "   [1.07654119e+00 1.07654119e+00 0.00000000e+00]]\n",
            "\n",
            "  [[7.46630630e+01 3.76630707e+01 2.86630688e+01]\n",
            "   [8.35865936e+01 4.65865898e+01 3.75865898e+01]\n",
            "   [7.47397537e+01 3.83826141e+01 2.91683254e+01]\n",
            "   ...\n",
            "   [2.14263916e-01 2.14263916e-01 0.00000000e+00]\n",
            "   [7.14416504e-02 7.14416504e-02 0.00000000e+00]\n",
            "   [2.28576660e+00 2.28576660e+00 3.31671268e-01]]\n",
            "\n",
            "  [[6.58622437e+01 2.88622456e+01 1.98622456e+01]\n",
            "   [6.71939011e+01 3.01938972e+01 2.11938972e+01]\n",
            "   [7.32193756e+01 3.92193756e+01 2.92193756e+01]\n",
            "   ...\n",
            "   [2.14263916e-01 2.14263916e-01 0.00000000e+00]\n",
            "   [7.14416504e-02 7.14416504e-02 0.00000000e+00]\n",
            "   [2.35717773e+00 2.35717773e+00 3.57177734e-01]]]\n",
            "\n",
            "\n",
            " [[[4.74540825e+01 3.44540825e+01 1.74540825e+01]\n",
            "   [5.34948959e+01 4.04948959e+01 2.34948978e+01]\n",
            "   [4.99234695e+01 3.69234695e+01 1.99234695e+01]\n",
            "   ...\n",
            "   [1.16986980e+01 1.39129620e+01 8.48443413e+00]\n",
            "   [1.37780324e-01 2.11226535e+00 9.18535516e-02]\n",
            "   [8.26485753e-01 2.23972869e+00 1.23972869e+00]]\n",
            "\n",
            "  [[4.47397957e+01 3.17397957e+01 1.47397957e+01]\n",
            "   [4.98622475e+01 3.68622475e+01 1.98622456e+01]\n",
            "   [5.87142830e+01 4.57142830e+01 2.87142849e+01]\n",
            "   ...\n",
            "   [2.84794712e+01 3.07498589e+01 2.51784725e+01]\n",
            "   [3.18362832e+00 5.11728954e+00 2.25506997e+00]\n",
            "   [3.82690430e-01 1.73986816e+00 7.39868164e-01]]\n",
            "\n",
            "  [[5.20153046e+01 3.90153046e+01 2.20153065e+01]\n",
            "   [5.51836739e+01 4.21836739e+01 2.51836739e+01]\n",
            "   [5.93367348e+01 4.63367348e+01 2.93367348e+01]\n",
            "   ...\n",
            "   [2.90918713e+01 3.20918694e+01 2.46633434e+01]\n",
            "   [1.53723221e+01 1.73723221e+01 1.28162022e+01]\n",
            "   [6.58150792e-01 2.23976350e+00 2.29614154e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.32989777e+02 1.26989777e+02 1.12989777e+02]\n",
            "   [1.32428589e+02 1.26428589e+02 1.12428589e+02]\n",
            "   [1.33188751e+02 1.27188751e+02 1.13188751e+02]\n",
            "   ...\n",
            "   [8.29999695e+01 8.49999695e+01 7.24285583e+01]\n",
            "   [8.16580734e+01 8.38723679e+01 7.13009567e+01]\n",
            "   [7.22855835e+01 7.60712891e+01 6.27141724e+01]]\n",
            "\n",
            "  [[1.29454041e+02 1.23454041e+02 1.09454041e+02]\n",
            "   [1.31280563e+02 1.25280556e+02 1.11280556e+02]\n",
            "   [1.27484627e+02 1.21484627e+02 1.07484627e+02]\n",
            "   ...\n",
            "   [8.20153046e+01 8.40153046e+01 7.30153046e+01]\n",
            "   [7.60611801e+01 7.90611801e+01 6.80611801e+01]\n",
            "   [7.08570557e+01 7.38570557e+01 6.28570557e+01]]\n",
            "\n",
            "  [[1.29459183e+02 1.23459183e+02 1.09459183e+02]\n",
            "   [1.26739807e+02 1.20739807e+02 1.06739807e+02]\n",
            "   [1.27147949e+02 1.21147949e+02 1.07147949e+02]\n",
            "   ...\n",
            "   [7.78571167e+01 8.06428528e+01 6.96428528e+01]\n",
            "   [7.15000305e+01 7.45000305e+01 6.35000305e+01]\n",
            "   [7.06427612e+01 7.36427612e+01 6.26427612e+01]]]], shape=(32, 224, 224, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the image arrays come out as tensors of pixel values where as the labels come out as one-hot encodings (e.g. `[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]` for `hamburger`)"
      ],
      "metadata": {
        "id": "_cbnmJ4Gx3cY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Building a transfer learning model using the Keras Functional API\n",
        "\n",
        "Let's build a model.\n",
        "\n",
        "To do so we're going to be using the `tf.keras.applications` module as it contains a series of already trained (on ImageNet) computer vision models as well as the Keras Functional API to construct our model.\n",
        "\n",
        "We're going to go through the following steps:\n",
        "\n",
        "1. Instantiate a pre-trained base model object by choosing a target model such as `EfficientNetB0` from `tf.keras.applications`, setting the `include_top` parameter to `False` (we do this because we're going to create our own top, which are the output layers for the model).\n",
        "2. Set the base model's `trainable` attribute to `False` to freeze all the weights in the pre-trained model.\n",
        "3. Define an input layer for our model, for example, what shape of data should our model expect?\n",
        "4. [Optional] Normalize the inputs to our model if it requires. Some computer vision models such as `ResNetV250` require their inputs to be between 0 & 1.\n",
        "> **Note :** As of writing, the `EfficientNetB0` models in `tf.keras.applications` module do not require images to be normalized on input, where as many of the other models do. \n",
        "\n",
        "5. Pass the inputs to the base model.\n",
        "6. Pool the outputs of the base model into a shape compatible with the output activation layer (turn base model output tensors into same shape as label tensors). This can be done using `tf.keras.layers.GlobalAveragePooling2D()` or `tf.keras.layers.GlobalMaxPooling2D()` though the former is more common in practice).\n",
        "7. Create an output activation layer using `tf.keras.layers.Dense()` with the appropriate activation function and number of neurons.\n",
        "8. Combine the inputs and outputs layer into a model using `tf.keras.Model()`\n",
        "9. Compile the model using the appropriate loss function and choose of optimizer.\n",
        "10. Fit the model for desired number of epochs and with necessary callbacks."
      ],
      "metadata": {
        "id": "DPAvgDhUy5-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create the base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create inputs into our model\n",
        "inputs = tf.keras.layers.Input(shape=IMG_SIZE + (3,), name='inputLayer')\n",
        "\n",
        "# 4. If using a model like ResNet50V2 you will need to normalize inputs \n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1/255.)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to the base_model\n",
        "x = base_model(inputs)\n",
        "# Check data shape after passing it to base_model\n",
        "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling_layer')(x)\n",
        "\n",
        "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(len(train_data_10_percent.class_names), activation=\"softmax\", name=\"outputLayer\")(x)\n",
        "\n",
        "# 8. Combine the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlsgCMdIeXr6",
        "outputId": "82203bef-d8b6-4ab4-d74f-8d2ddc64055f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Shape after passing inputs through base model: (None, 7, 7, 1280)\n",
            "Shape after GlobalAveragePooling2D: (None, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile our model\n",
        "model_0.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "4fmaPeafgtE4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit our model\n",
        "history_model0 = model_0.fit(train_data_10_percent,\n",
        "                             epochs=5,\n",
        "                             steps_per_epoch=len(train_data_10_percent),\n",
        "                             validation_data=test_data_10_percent,\n",
        "                             validation_steps=int(0.25*len(test_data_10_percent)), # validate on only 25% of test_data (validate quicker)\n",
        "                             callbacks=[create_tensorboard_callback(\"transfer_learning\",\"10_percent_feature_extract\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMB2GvHnhsAk",
        "outputId": "5f2fc83b-8525-49c8-df54-35b7c8d9ae00"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :transfer_learning/10_percent_feature_extract/2022-10-08_13:37:01\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 20s 253ms/step - loss: 1.9606 - accuracy: 0.3613 - val_loss: 1.3662 - val_accuracy: 0.7171\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 4s 152ms/step - loss: 1.1801 - accuracy: 0.7413 - val_loss: 0.9121 - val_accuracy: 0.8339\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 4s 149ms/step - loss: 0.8512 - accuracy: 0.8107 - val_loss: 0.7259 - val_accuracy: 0.8405\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 5s 184ms/step - loss: 0.7061 - accuracy: 0.8240 - val_loss: 0.6463 - val_accuracy: 0.8503\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 4s 148ms/step - loss: 0.6045 - accuracy: 0.8587 - val_loss: 0.5792 - val_accuracy: 0.8618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the full test dataset\n",
        "model_0.evaluate(test_data_10_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUVQgPb3ibjz",
        "outputId": "6c8848c1-6048-4987-8e86-121c77b65f41"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 6s 75ms/step - loss: 0.6121 - accuracy: 0.8400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.612060546875, 0.8399999737739563]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After a minute or so of training our model performs incredibly well on the training and test sets. \n",
        "\n",
        "It's important to note the kind of transfer learning we used here is called **feature extraction** transfer learning, similar to what we did with the TensorFlow Hub models.\n",
        "\n",
        "In other words, we passed our custom data to an already pre-trained model (`EfficientNetB0`), asked it \"what patterns do you see?\" and then put our own output layer on top to make sure the outputs were tailored to our desired number of classes.\n",
        "\n",
        "We also used the Keras Functional API to build our model rather than the Sequential API. For now, the benefits of this main not seem clear but when you start to build more sophisticated models, you'll probably want to use the Functional API. So it's important to have exposure to this way of building models."
      ],
      "metadata": {
        "id": "5OGyvl_Fk0M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the layers in our base model\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHezlAE2j14I",
        "outputId": "a75cbfcc-6944-48f0-bef8-1914b8b9b25e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1\n",
            "1 rescaling\n",
            "2 normalization\n",
            "3 stem_conv_pad\n",
            "4 stem_conv\n",
            "5 stem_bn\n",
            "6 stem_activation\n",
            "7 block1a_dwconv\n",
            "8 block1a_bn\n",
            "9 block1a_activation\n",
            "10 block1a_se_squeeze\n",
            "11 block1a_se_reshape\n",
            "12 block1a_se_reduce\n",
            "13 block1a_se_expand\n",
            "14 block1a_se_excite\n",
            "15 block1a_project_conv\n",
            "16 block1a_project_bn\n",
            "17 block2a_expand_conv\n",
            "18 block2a_expand_bn\n",
            "19 block2a_expand_activation\n",
            "20 block2a_dwconv_pad\n",
            "21 block2a_dwconv\n",
            "22 block2a_bn\n",
            "23 block2a_activation\n",
            "24 block2a_se_squeeze\n",
            "25 block2a_se_reshape\n",
            "26 block2a_se_reduce\n",
            "27 block2a_se_expand\n",
            "28 block2a_se_excite\n",
            "29 block2a_project_conv\n",
            "30 block2a_project_bn\n",
            "31 block2b_expand_conv\n",
            "32 block2b_expand_bn\n",
            "33 block2b_expand_activation\n",
            "34 block2b_dwconv\n",
            "35 block2b_bn\n",
            "36 block2b_activation\n",
            "37 block2b_se_squeeze\n",
            "38 block2b_se_reshape\n",
            "39 block2b_se_reduce\n",
            "40 block2b_se_expand\n",
            "41 block2b_se_excite\n",
            "42 block2b_project_conv\n",
            "43 block2b_project_bn\n",
            "44 block2b_drop\n",
            "45 block2b_add\n",
            "46 block3a_expand_conv\n",
            "47 block3a_expand_bn\n",
            "48 block3a_expand_activation\n",
            "49 block3a_dwconv_pad\n",
            "50 block3a_dwconv\n",
            "51 block3a_bn\n",
            "52 block3a_activation\n",
            "53 block3a_se_squeeze\n",
            "54 block3a_se_reshape\n",
            "55 block3a_se_reduce\n",
            "56 block3a_se_expand\n",
            "57 block3a_se_excite\n",
            "58 block3a_project_conv\n",
            "59 block3a_project_bn\n",
            "60 block3b_expand_conv\n",
            "61 block3b_expand_bn\n",
            "62 block3b_expand_activation\n",
            "63 block3b_dwconv\n",
            "64 block3b_bn\n",
            "65 block3b_activation\n",
            "66 block3b_se_squeeze\n",
            "67 block3b_se_reshape\n",
            "68 block3b_se_reduce\n",
            "69 block3b_se_expand\n",
            "70 block3b_se_excite\n",
            "71 block3b_project_conv\n",
            "72 block3b_project_bn\n",
            "73 block3b_drop\n",
            "74 block3b_add\n",
            "75 block4a_expand_conv\n",
            "76 block4a_expand_bn\n",
            "77 block4a_expand_activation\n",
            "78 block4a_dwconv_pad\n",
            "79 block4a_dwconv\n",
            "80 block4a_bn\n",
            "81 block4a_activation\n",
            "82 block4a_se_squeeze\n",
            "83 block4a_se_reshape\n",
            "84 block4a_se_reduce\n",
            "85 block4a_se_expand\n",
            "86 block4a_se_excite\n",
            "87 block4a_project_conv\n",
            "88 block4a_project_bn\n",
            "89 block4b_expand_conv\n",
            "90 block4b_expand_bn\n",
            "91 block4b_expand_activation\n",
            "92 block4b_dwconv\n",
            "93 block4b_bn\n",
            "94 block4b_activation\n",
            "95 block4b_se_squeeze\n",
            "96 block4b_se_reshape\n",
            "97 block4b_se_reduce\n",
            "98 block4b_se_expand\n",
            "99 block4b_se_excite\n",
            "100 block4b_project_conv\n",
            "101 block4b_project_bn\n",
            "102 block4b_drop\n",
            "103 block4b_add\n",
            "104 block4c_expand_conv\n",
            "105 block4c_expand_bn\n",
            "106 block4c_expand_activation\n",
            "107 block4c_dwconv\n",
            "108 block4c_bn\n",
            "109 block4c_activation\n",
            "110 block4c_se_squeeze\n",
            "111 block4c_se_reshape\n",
            "112 block4c_se_reduce\n",
            "113 block4c_se_expand\n",
            "114 block4c_se_excite\n",
            "115 block4c_project_conv\n",
            "116 block4c_project_bn\n",
            "117 block4c_drop\n",
            "118 block4c_add\n",
            "119 block5a_expand_conv\n",
            "120 block5a_expand_bn\n",
            "121 block5a_expand_activation\n",
            "122 block5a_dwconv\n",
            "123 block5a_bn\n",
            "124 block5a_activation\n",
            "125 block5a_se_squeeze\n",
            "126 block5a_se_reshape\n",
            "127 block5a_se_reduce\n",
            "128 block5a_se_expand\n",
            "129 block5a_se_excite\n",
            "130 block5a_project_conv\n",
            "131 block5a_project_bn\n",
            "132 block5b_expand_conv\n",
            "133 block5b_expand_bn\n",
            "134 block5b_expand_activation\n",
            "135 block5b_dwconv\n",
            "136 block5b_bn\n",
            "137 block5b_activation\n",
            "138 block5b_se_squeeze\n",
            "139 block5b_se_reshape\n",
            "140 block5b_se_reduce\n",
            "141 block5b_se_expand\n",
            "142 block5b_se_excite\n",
            "143 block5b_project_conv\n",
            "144 block5b_project_bn\n",
            "145 block5b_drop\n",
            "146 block5b_add\n",
            "147 block5c_expand_conv\n",
            "148 block5c_expand_bn\n",
            "149 block5c_expand_activation\n",
            "150 block5c_dwconv\n",
            "151 block5c_bn\n",
            "152 block5c_activation\n",
            "153 block5c_se_squeeze\n",
            "154 block5c_se_reshape\n",
            "155 block5c_se_reduce\n",
            "156 block5c_se_expand\n",
            "157 block5c_se_excite\n",
            "158 block5c_project_conv\n",
            "159 block5c_project_bn\n",
            "160 block5c_drop\n",
            "161 block5c_add\n",
            "162 block6a_expand_conv\n",
            "163 block6a_expand_bn\n",
            "164 block6a_expand_activation\n",
            "165 block6a_dwconv_pad\n",
            "166 block6a_dwconv\n",
            "167 block6a_bn\n",
            "168 block6a_activation\n",
            "169 block6a_se_squeeze\n",
            "170 block6a_se_reshape\n",
            "171 block6a_se_reduce\n",
            "172 block6a_se_expand\n",
            "173 block6a_se_excite\n",
            "174 block6a_project_conv\n",
            "175 block6a_project_bn\n",
            "176 block6b_expand_conv\n",
            "177 block6b_expand_bn\n",
            "178 block6b_expand_activation\n",
            "179 block6b_dwconv\n",
            "180 block6b_bn\n",
            "181 block6b_activation\n",
            "182 block6b_se_squeeze\n",
            "183 block6b_se_reshape\n",
            "184 block6b_se_reduce\n",
            "185 block6b_se_expand\n",
            "186 block6b_se_excite\n",
            "187 block6b_project_conv\n",
            "188 block6b_project_bn\n",
            "189 block6b_drop\n",
            "190 block6b_add\n",
            "191 block6c_expand_conv\n",
            "192 block6c_expand_bn\n",
            "193 block6c_expand_activation\n",
            "194 block6c_dwconv\n",
            "195 block6c_bn\n",
            "196 block6c_activation\n",
            "197 block6c_se_squeeze\n",
            "198 block6c_se_reshape\n",
            "199 block6c_se_reduce\n",
            "200 block6c_se_expand\n",
            "201 block6c_se_excite\n",
            "202 block6c_project_conv\n",
            "203 block6c_project_bn\n",
            "204 block6c_drop\n",
            "205 block6c_add\n",
            "206 block6d_expand_conv\n",
            "207 block6d_expand_bn\n",
            "208 block6d_expand_activation\n",
            "209 block6d_dwconv\n",
            "210 block6d_bn\n",
            "211 block6d_activation\n",
            "212 block6d_se_squeeze\n",
            "213 block6d_se_reshape\n",
            "214 block6d_se_reduce\n",
            "215 block6d_se_expand\n",
            "216 block6d_se_excite\n",
            "217 block6d_project_conv\n",
            "218 block6d_project_bn\n",
            "219 block6d_drop\n",
            "220 block6d_add\n",
            "221 block7a_expand_conv\n",
            "222 block7a_expand_bn\n",
            "223 block7a_expand_activation\n",
            "224 block7a_dwconv\n",
            "225 block7a_bn\n",
            "226 block7a_activation\n",
            "227 block7a_se_squeeze\n",
            "228 block7a_se_reshape\n",
            "229 block7a_se_reduce\n",
            "230 block7a_se_expand\n",
            "231 block7a_se_excite\n",
            "232 block7a_project_conv\n",
            "233 block7a_project_bn\n",
            "234 top_conv\n",
            "235 top_bn\n",
            "236 top_activation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of the base_model\n",
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHM6o62amDfr",
        "outputId": "52fb1151-d733-488b-94ed-00ad10e331b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnetb0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, None, None,   0           ['input_1[0][0]']                \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, None, None,   7           ['rescaling[0][0]']              \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, None, None,   0           ['normalization[0][0]']          \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, None, None,   864         ['stem_conv_pad[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, None, None,   128         ['stem_conv[0][0]']              \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, None, None,   0           ['stem_bn[0][0]']                \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, None, None,   288        ['stem_activation[0][0]']        \n",
            " D)                             32)                                                               \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, None, None,   128        ['block1a_dwconv[0][0]']         \n",
            " )                              32)                                                               \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, None, None,   0          ['block1a_bn[0][0]']             \n",
            " )                              32)                                                               \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, None, None,   0           ['block1a_activation[0][0]',     \n",
            "                                32)                               'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, None, None,   512         ['block1a_se_excite[0][0]']      \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, None, None,   64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      16)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, None, None,   1536        ['block1a_project_bn[0][0]']     \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, None, None,   384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       96)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, None, None,   0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       96)                                                               \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           96)                              ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, None, None,   864        ['block2a_dwconv_pad[0][0]']     \n",
            " D)                             96)                                                               \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, None, None,   384        ['block2a_dwconv[0][0]']         \n",
            " )                              96)                                                               \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, None, None,   0          ['block2a_bn[0][0]']             \n",
            " )                              96)                                                               \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, None, None,   0           ['block2a_activation[0][0]',     \n",
            "                                96)                               'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, None, None,   2304        ['block2a_se_excite[0][0]']      \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, None, None,   96         ['block2a_project_conv[0][0]']   \n",
            " lization)                      24)                                                               \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, None, None,   3456        ['block2a_project_bn[0][0]']     \n",
            "                                144)                                                              \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, None, None,   576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                       144)                                                              \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, None, None,   0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                       144)                                                              \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, None, None,   1296       ['block2b_expand_activation[0][0]\n",
            " D)                             144)                             ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, None, None,   576        ['block2b_dwconv[0][0]']         \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, None, None,   0          ['block2b_bn[0][0]']             \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, None, None,   0           ['block2b_activation[0][0]',     \n",
            "                                144)                              'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, None, None,   3456        ['block2b_se_excite[0][0]']      \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, None, None,   96         ['block2b_project_conv[0][0]']   \n",
            " lization)                      24)                                                               \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, None, None,   0           ['block2b_project_bn[0][0]']     \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, None, None,   0           ['block2b_drop[0][0]',           \n",
            "                                24)                               'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, None, None,   3456        ['block2b_add[0][0]']            \n",
            "                                144)                                                              \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, None, None,   576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                       144)                                                              \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, None, None,   0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                       144)                                                              \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block3a_expand_activation[0][0]\n",
            " g2D)                           144)                             ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, None, None,   3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                             144)                                                              \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, None, None,   576        ['block3a_dwconv[0][0]']         \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, None, None,   0          ['block3a_bn[0][0]']             \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, None, None,   0           ['block3a_activation[0][0]',     \n",
            "                                144)                              'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, None, None,   5760        ['block3a_se_excite[0][0]']      \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, None, None,   160        ['block3a_project_conv[0][0]']   \n",
            " lization)                      40)                                                               \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, None, None,   9600        ['block3a_project_bn[0][0]']     \n",
            "                                240)                                                              \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, None, None,   960        ['block3b_expand_conv[0][0]']    \n",
            " ization)                       240)                                                              \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, None, None,   0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                       240)                                                              \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, None, None,   6000       ['block3b_expand_activation[0][0]\n",
            " D)                             240)                             ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, None, None,   960        ['block3b_dwconv[0][0]']         \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, None, None,   0          ['block3b_bn[0][0]']             \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, None, None,   0           ['block3b_activation[0][0]',     \n",
            "                                240)                              'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, None, None,   9600        ['block3b_se_excite[0][0]']      \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, None, None,   160        ['block3b_project_conv[0][0]']   \n",
            " lization)                      40)                                                               \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, None, None,   0           ['block3b_project_bn[0][0]']     \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, None, None,   0           ['block3b_drop[0][0]',           \n",
            "                                40)                               'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, None, None,   9600        ['block3b_add[0][0]']            \n",
            "                                240)                                                              \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, None, None,   960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                       240)                                                              \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, None, None,   0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                       240)                                                              \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block4a_expand_activation[0][0]\n",
            " g2D)                           240)                             ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, None, None,   2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                             240)                                                              \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, None, None,   960        ['block4a_dwconv[0][0]']         \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, None, None,   0          ['block4a_bn[0][0]']             \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, None, None,   0           ['block4a_activation[0][0]',     \n",
            "                                240)                              'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, None, None,   19200       ['block4a_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, None, None,   320        ['block4a_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, None, None,   38400       ['block4a_project_bn[0][0]']     \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, None, None,   1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, None, None,   0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, None, None,   4320       ['block4b_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, None, None,   1920       ['block4b_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, None, None,   0          ['block4b_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, None, None,   0           ['block4b_activation[0][0]',     \n",
            "                                480)                              'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, None, None,   38400       ['block4b_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, None, None,   320        ['block4b_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, None, None,   0           ['block4b_project_bn[0][0]']     \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, None, None,   0           ['block4b_drop[0][0]',           \n",
            "                                80)                               'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, None, None,   38400       ['block4b_add[0][0]']            \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, None, None,   1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, None, None,   0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, None, None,   4320       ['block4c_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, None, None,   1920       ['block4c_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, None, None,   0          ['block4c_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, None, None,   0           ['block4c_activation[0][0]',     \n",
            "                                480)                              'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, None, None,   38400       ['block4c_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, None, None,   320        ['block4c_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, None, None,   0           ['block4c_project_bn[0][0]']     \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, None, None,   0           ['block4c_drop[0][0]',           \n",
            "                                80)                               'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, None, None,   38400       ['block4c_add[0][0]']            \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, None, None,   1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, None, None,   0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, None, None,   12000      ['block5a_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, None, None,   1920       ['block5a_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, None, None,   0          ['block5a_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, None, None,   0           ['block5a_activation[0][0]',     \n",
            "                                480)                              'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, None, None,   53760       ['block5a_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, None, None,   448        ['block5a_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, None, None,   75264       ['block5a_project_bn[0][0]']     \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, None, None,   2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, None, None,   0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block5b_expand_activation[0][0]\n",
            " D)                             672)                             ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, None, None,   2688       ['block5b_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, None, None,   0          ['block5b_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, None, None,   0           ['block5b_activation[0][0]',     \n",
            "                                672)                              'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, None, None,   75264       ['block5b_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, None, None,   448        ['block5b_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, None, None,   0           ['block5b_project_bn[0][0]']     \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, None, None,   0           ['block5b_drop[0][0]',           \n",
            "                                112)                              'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, None, None,   75264       ['block5b_add[0][0]']            \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, None, None,   2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, None, None,   0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block5c_expand_activation[0][0]\n",
            " D)                             672)                             ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, None, None,   2688       ['block5c_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, None, None,   0          ['block5c_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, None, None,   0           ['block5c_activation[0][0]',     \n",
            "                                672)                              'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, None, None,   75264       ['block5c_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, None, None,   448        ['block5c_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, None, None,   0           ['block5c_project_bn[0][0]']     \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, None, None,   0           ['block5c_drop[0][0]',           \n",
            "                                112)                              'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, None, None,   75264       ['block5c_add[0][0]']            \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, None, None,   2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, None, None,   0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block6a_expand_activation[0][0]\n",
            " g2D)                           672)                             ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block6a_dwconv_pad[0][0]']     \n",
            " D)                             672)                                                              \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, None, None,   2688       ['block6a_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, None, None,   0          ['block6a_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, None, None,   0           ['block6a_activation[0][0]',     \n",
            "                                672)                              'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, None, None,   129024      ['block6a_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, None, None,   768        ['block6a_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, None, None,   221184      ['block6a_project_bn[0][0]']     \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, None, None,   4608       ['block6b_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, None, None,   0          ['block6b_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6b_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, None, None,   4608       ['block6b_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, None, None,   0          ['block6b_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, None, None,   0           ['block6b_activation[0][0]',     \n",
            "                                1152)                             'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, None, None,   221184      ['block6b_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, None, None,   768        ['block6b_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, None, None,   0           ['block6b_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, None, None,   0           ['block6b_drop[0][0]',           \n",
            "                                192)                              'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, None, None,   221184      ['block6b_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, None, None,   4608       ['block6c_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, None, None,   0          ['block6c_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6c_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, None, None,   4608       ['block6c_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, None, None,   0          ['block6c_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, None, None,   0           ['block6c_activation[0][0]',     \n",
            "                                1152)                             'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, None, None,   221184      ['block6c_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, None, None,   768        ['block6c_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, None, None,   0           ['block6c_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, None, None,   0           ['block6c_drop[0][0]',           \n",
            "                                192)                              'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, None, None,   221184      ['block6c_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, None, None,   4608       ['block6d_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, None, None,   0          ['block6d_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6d_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, None, None,   4608       ['block6d_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, None, None,   0          ['block6d_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, None, None,   0           ['block6d_activation[0][0]',     \n",
            "                                1152)                             'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, None, None,   221184      ['block6d_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, None, None,   768        ['block6d_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, None, None,   0           ['block6d_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, None, None,   0           ['block6d_drop[0][0]',           \n",
            "                                192)                              'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, None, None,   221184      ['block6d_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, None, None,   4608       ['block7a_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, None, None,   0          ['block7a_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, None, None,   10368      ['block7a_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, None, None,   4608       ['block7a_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, None, None,   0          ['block7a_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, None, None,   0           ['block7a_activation[0][0]',     \n",
            "                                1152)                             'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, None, None,   368640      ['block7a_se_excite[0][0]']      \n",
            "                                320)                                                              \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, None, None,   1280       ['block7a_project_conv[0][0]']   \n",
            " lization)                      320)                                                              \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, None, None,   409600      ['block7a_project_bn[0][0]']     \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, None, None,   5120        ['top_conv[0][0]']               \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, None, None,   0           ['top_bn[0][0]']                 \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,571\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,571\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of the model\n",
        "model_0.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN9jNvB2ki9D",
        "outputId": "5f63ed87-c6e3-4a2a-c448-22bb5f008207"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputLayer (InputLayer)     [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
            "                                                                 \n",
            " global_average_pooling_laye  (None, 1280)             0         \n",
            " r (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our overall model has five layers but really, one of those layers (`EfficientNetB0`) has 236 layers.\n",
        "\n",
        "You can see how the output shape started out as `(None,224,224,3)` for the input layer but was transformed to be `(None, 10)` by the output layer, where None is the placeholder for the batch size."
      ],
      "metadata": {
        "id": "yOz9j7Nmrp-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model's training curves\n",
        "plot_loss_curves(history_model0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "_ZPvJadkmBHv",
        "outputId": "943325fb-d32b-4d68-f67c-473bb50b28a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a feature vector from a trained model"
      ],
      "metadata": {
        "id": "eg6NHpGZsC2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `tf.keras.layers.GlobalAveragePooling2D()` layer transforms a 4D tensor into a 2D tensor by averaging the value across the inner-axes.\n",
        "\n",
        "Let's see an example."
      ],
      "metadata": {
        "id": "RC1cqUG9sKT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (1,4,4,3)\n",
        "\n",
        "# Create a random tensor\n",
        "tf.random.set_seed(42)\n",
        "input_tensor = tf.random.normal(input_shape)\n",
        "print(f\"Shape of the random tensor: {input_tensor.shape}\")\n",
        "print(f\"Random input_tensor:\\n {input_tensor}\\n\")\n",
        "\n",
        "# Pass the random tensor through a global average pooling 2D layer\n",
        "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
        "print(f\"Shape of the global average pooled random tensor: {global_average_pooled_tensor.shape}\")\n",
        "print(f\"2D global average pooled random tensor:\\n {global_average_pooled_tensor}\")\n"
      ],
      "metadata": {
        "id": "RIATyrEXp3GY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56b65c3-3b8b-45cd-a1e9-270e0fbfe00f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the random tensor: (1, 4, 4, 3)\n",
            "Random input_tensor:\n",
            " [[[[ 0.3274685  -0.8426258   0.3194337 ]\n",
            "   [-1.4075519  -2.3880599  -1.0392479 ]\n",
            "   [-0.5573232   0.539707    1.6994323 ]\n",
            "   [ 0.28893656 -1.5066116  -0.2645474 ]]\n",
            "\n",
            "  [[-0.59722406 -1.9171132  -0.62044144]\n",
            "   [ 0.8504023  -0.40604794 -3.0258412 ]\n",
            "   [ 0.9058464   0.29855987 -0.22561555]\n",
            "   [-0.7616443  -1.8917141  -0.93847126]]\n",
            "\n",
            "  [[ 0.77852213 -0.47338897  0.97772694]\n",
            "   [ 0.24694404  0.20573747 -0.5256233 ]\n",
            "   [ 0.32410017  0.02545409 -0.10638497]\n",
            "   [-0.6369475   1.1603122   0.2507359 ]]\n",
            "\n",
            "  [[-0.41728503  0.4012578  -1.4145443 ]\n",
            "   [-0.5931857  -1.6617213   0.33567193]\n",
            "   [ 0.10815629  0.23479682 -0.56668764]\n",
            "   [-0.35819843  0.88698614  0.52744764]]]]\n",
            "\n",
            "Shape of the global average pooled random tensor: (1, 3)\n",
            "2D global average pooled random tensor:\n",
            " [[-0.09368646 -0.45840448 -0.2885598 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the `tf.keras.layers.GlobalAveragePooling2D()` layer condensed  the input tensor from shape `(1,4,4,3)` to `(1,3)`. It did so by averaging the `input_tensor` accross the middle axes.\n",
        "\n",
        "We can replicate this operation using the `tf.reduce_mean()` operation and specifyind the appropriate axes."
      ],
      "metadata": {
        "id": "PwNgHKIUvYeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's replicate the GlobalAveragePooling2D layer\n",
        "tf.reduce_mean(input_tensor, axis=[1,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2tLP9zTtm8H",
        "outputId": "2b62d030-18de-465c-f4c5-3e8ff85cfbf8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.09368646, -0.45840448, -0.2885598 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with GlobalMaxPool2D\n",
        "global_max_pooled_tensor = tf.keras.layers.GlobalMaxPool2D()(input_tensor)\n",
        "print(f\"Global max pooled tensor:\\n {global_max_pooled_tensor}\\n\")\n",
        "\n",
        "# Replicate the GlobalMaxPool2D layer with tf.reduce_max\n",
        "reduce_max_tensor = tf.reduce_max(input_tensor, axis=[1,2])\n",
        "print(f\"Reduce max pooled tensor:\\n {reduce_max_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdqoiETuv4xj",
        "outputId": "d54751c1-1b68-4496-bcf4-5792dc85c30b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global max pooled tensor:\n",
            " [[0.9058464 1.1603122 1.6994323]]\n",
            "\n",
            "Reduce max pooled tensor:\n",
            " [[0.9058464 1.1603122 1.6994323]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing this not only makes the ouput of the base model compatible with the input shape requirement of our output layer (`tf.keras.layers.Dense())`, it also condenses the information found by the base model into a lower dimension **feature vector**."
      ],
      "metadata": {
        "id": "uushqMByxlWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a series of transfer learning experiments"
      ],
      "metadata": {
        "id": "Fk6NA50Zx1p5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've seen the incredible results of transfer learning on 10% of the training data, what about 1% of the training data ?\n",
        "\n",
        "What kind of results do you think we can get using 100x less data than the original CNN models we build ourselves?\n",
        "\n",
        "Why don't we answer that question while running the following modelling experiments:\n",
        "\n",
        "1. `model_1`: USe feature extraction transfer learning on 1% of the training data with data augmentation.\n",
        "2. `model_2`: Use feature extraction transfer learning on 10% of the training data with data augmentation.\n",
        "3. `model_3`: Use fine-tuning transfer learning on 10% of the training data with data augmentation.\n",
        "4. `model_4`: Use fine-tuning transfer learning on 100% of the training data with data augmentation.\n",
        "\n",
        "While all of the experiments will be run on different versions of the training data, they will all be evaluated on the same test dataset, this ensures the results of each experiment are as comparable as possible.\n",
        "\n",
        "All experiments will be done using the `EfficientNetB0` model within the `tf.keras.applications` module.\n",
        "\n",
        "To make sure we're keeping track of our experiments, we'll use our `create_tensorboard_callback()` function to log all of the model training logs.\n",
        "\n",
        "We'll construct each model using the Keras Functional API and instead of implementing data augmentation in the `ImageDataGenerator` class as we have previously, we're going to build it right into the model using the `tf.keras.layers.experimental.preprocessing` module.\n",
        "\n",
        "Let's begin by downloading the data for experiment 1, using feature extraction transfer learning on 1% of the training data with data augmentation."
      ],
      "metadata": {
        "id": "_mpzz95Z0BGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and preprocessed data for model 1"
      ],
      "metadata": {
        "id": "P_FULmz4466g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip"
      ],
      "metadata": {
        "id": "k7GTeYxFxCnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a2378d-75a5-4512-e4ab-9b3ae1a2a290"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-08 13:51:26--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 173.194.217.128, 173.194.218.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133612354 (127M) [application/zip]\n",
            "Saving to: ‘10_food_classes_1_percent.zip’\n",
            "\n",
            "10_food_classes_1_p 100%[===================>] 127.42M   171MB/s    in 0.7s    \n",
            "\n",
            "2022-10-08 13:51:26 (171 MB/s) - ‘10_food_classes_1_percent.zip’ saved [133612354/133612354]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip data\n",
        "unzip_data(\"10_food_classes_1_percent.zip\")"
      ],
      "metadata": {
        "id": "GhIOpiCC3ZtE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test dirs\n",
        "train_dir_1_percent = \"10_food_classes_1_percent/train\"\n",
        "test_dir = \"10_food_classes_1_percent/test\""
      ],
      "metadata": {
        "id": "OsHqrM8t3rZS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# walkthroug the data\n",
        "walk_through_dir(\"10_food_classes_1_percent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jtCDye53jLT",
        "outputId": "370b46be-d85e-4224-8fe3-a3da87e7fe9f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10_food_classes_1_percent: There are 2 directories and 0 files\n",
            "10_food_classes_1_percent/test: There are 10 directories and 0 files\n",
            "10_food_classes_1_percent/test/chicken_wings: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/steak: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/hamburger: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/fried_rice: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/ice_cream: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/chicken_curry: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/ramen: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/sushi: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/grilled_salmon: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/test/pizza: There are 0 directories and 250 files\n",
            "10_food_classes_1_percent/train: There are 10 directories and 0 files\n",
            "10_food_classes_1_percent/train/chicken_wings: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/steak: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/hamburger: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/fried_rice: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/ice_cream: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/chicken_curry: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/ramen: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/sushi: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/grilled_salmon: There are 0 directories and 7 files\n",
            "10_food_classes_1_percent/train/pizza: There are 0 directories and 7 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to load our images in as `tf.data.Dataset` objects, to do so, we'll use the `image_dataset_from_directory()` method."
      ],
      "metadata": {
        "id": "lp9jQJ5K4pzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data loaders\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,\n",
        "                                                                           label_mode='categorical',\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode='categorical',\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoPce-jr346j",
        "outputId": "b022ecb0-c75b-40c5-ae97-649c0bba5b47"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 70 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding data augmentation right into the model"
      ],
      "metadata": {
        "id": "3SpW3Wu5410m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously we've used the different parameters of the `ImageDataGenerator` class to augment our training images, this time we're going to build data augmentation right into the model.\n",
        "\n",
        "How ?\n",
        "\n",
        "Using the `tf.keras.layers.experimental.preprocessing` module and creating a dedicated data augmentation layer.\n",
        "\n",
        "This is a relatively new feature added to TensorFlow 2.2+ but it's very powerful. Adding a data augmentation layer to the model has the following benefits:\n",
        "\n",
        "- Preprocessing of the images (augmenting them) happens on the GPU rather on the CPU (much faster).\n",
        "  - Images are best preprocessed on the GPU where as text and structured data are more suited to be preprocessed on the CPU.\n",
        "- Image data augmentation only happens during training so we can still export our whole model and use it elsewhere. And if someone else wanted to train the same model as us, including the same kind of data augmentation, they could.\n",
        "\n",
        "![](https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/images/05-data-augmentation-inside-a-model.png)\n",
        "\n",
        ">🤔 Note: At the time of writing, the preprocessing layers we're using for data augmentation are in experimental status within the in TensorFlow library. This means although the layers should be considered stable, the code may change slightly in a future version of TensorFlow. For more information on the other preprocessing layers avaiable and the different methods of data augmentation, check out the [Keras preprocessing layers guide](https://keras.io/guides/preprocessing_layers/) and the [TensorFlow data augmentation guide](https://www.tensorflow.org/tutorials/images/data_augmentation).\n",
        "\n",
        "To use data augmentation right within our model we'll create a Keras Sequential model consisting of only data preprocessing layers, we can then use this Sequential model within another Functional model.\n",
        "\n",
        "The data augmentation transformations we're going to use are:\n",
        "- **RandomFlip** - flips image on horizontal or vertical axis.\n",
        "- **RandomRotation** - randomly rotates image by a specified amount.\n",
        "- **RandomZoom** - randomly zooms into an image by specified amount.\n",
        "- **RandomHeight** - randomly shifts image height by a specified amount.\n",
        "- **RandomWidth** - randomly shifts image width by a specified amount.\n",
        "- **Rescaling** - normalizes the image pixel values to be between 0 and 1, this is worth mentioning because it is required for some image models but since we're using the `tf.keras.applications` implementation of `EfficientNetB0`, it's not required.\n"
      ],
      "metadata": {
        "id": "yMvyxCXJ5lsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers. experimental import preprocessing"
      ],
      "metadata": {
        "id": "9ktS3rBP-y2d"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create data augmentation stage with horizontal flipping, rotations, zooms, etc.\n",
        "data_augmentation = keras.Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\"),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomWidth(0.2),\n",
        "    # preprocessing.Rescaling(1/255.)  # keep for models like ResNet50V2, remove for EfficientNetB0\n",
        "], name=\"data_augmentation\")"
      ],
      "metadata": {
        "id": "WeGIr7hG4lRm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rki5XvXV_MyK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}