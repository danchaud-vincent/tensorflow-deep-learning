{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOa7PE8bM4oszpmmXRVIdOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danchaud-vincent/tensorflow-deep-learning/blob/main/05_Transfer_learning_in_tensorflow_part2_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 05. Transfer Learning with TensorFlow Part 2: Fine-tuning"
      ],
      "metadata": {
        "id": "oKfQArbiYHeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food Vision project than building our own models (even with less data).\n",
        "\n",
        "Now we're going to cover another type of transfer learning: fine-tuning.\n",
        "\n",
        "In **fine-tuning transfer learning** the pre-trained model weights from another model are unfrozen and tweaked during to better suit your own data.\n",
        "\n",
        "For feature extraction transfer learning, you may only train the top 1-3 layers of a pre-trained model with your own data, in fine-tuning transfer learning, you might train 1-3+ of pre-trained model.\n",
        "\n",
        "![](https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/images/05-transfer-learning-feature-extraction-vs-fine-tuning.png)"
      ],
      "metadata": {
        "id": "ezI2AdvMYFI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What we're going to cover\n",
        "\n",
        "We're going to go through the follow with TensorFlow:\n",
        "- Introduce fine-tuning, a type of transfer learning to modify a pre-trained model to be more suited to your data.\n",
        "- Using the Keras Functional API (a different way to build models in Keras)\n",
        "- Using a smaller dataset to experiment faster (e.g. 1-10% of training samples of 10 classes of food)\n",
        "- Data augmentation (how to make your training dataset more diverse without adding more data)\n",
        "- Running a series of modelling experiments on our Food Vision data:\n",
        "  - Model 0: a transfer learning model using Keras Functional API\n",
        "  - Model 1: a feature extraction transfer learning model on 1% of the data with data augmentation\n",
        "  - Model 2 : a feature extraction transfer learning model on 10 % of the data with data augmentation\n",
        "  - Model 3: a fine-tuned transfer learning model on 10% of the data\n",
        "  - Model 4: a fine-tuned transfer learning model on 100% of the data\n",
        "- Introduce the ModelCheckpoint callback to save intermediate training results\n",
        "- Compare model experiments results using TensorBoard"
      ],
      "metadata": {
        "id": "dsqKUaq6jTdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a GPU?\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQaOixQWkW0Y",
        "outputId": "fa6edae6-9786-4a05-b743-41a526c2bf83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 30 18:16:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions\n",
        "\n",
        "Throughout your machine learning experiments, you'll likely come accross snippets of code you want to use over and over again.\n",
        "\n",
        "For example, a plotting function which plots a model's `history` object (see `plot_loss_curves()` below).\n",
        "\n",
        "You could recreate these functions over and over again. But as you might have guessed, rewritting the same functions becomes tedious.\n",
        "\n",
        "One of the solutions is to store them in a helper functions script such as `helper_functions.py`. And then import the necessary functionality when you need it.\n",
        "\n",
        "\n",
        "Let's see what this looks like."
      ],
      "metadata": {
        "id": "M0HG8i19jTUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from course GitHub\n",
        "!wget https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/utils/helper_functions.py "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BmHk2qUtmve",
        "outputId": "87137778-fef0-4631-ff6f-94fafc239503"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-30 18:16:24--  https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/utils/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2614 (2.6K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]   2.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-30 18:16:25 (51.1 MB/s) - ‘helper_functions.py’ saved [2614/2614]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import Helper functions we're going to use\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, walk_through_dir, unzip_data"
      ],
      "metadata": {
        "id": "gQnBafFPtwpi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1O Food Classes: Working with less data"
      ],
      "metadata": {
        "id": "oJuX3A_EjhCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw in the previous notebook that we could get great results with only 10% of the training data using transfer learning with TensorFlow Hub.\n",
        "\n",
        "In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use the in-built pretrained models within the `tf.keras.applications` module as well as how to fine-tune them to our own custom dataset.\n",
        "\n",
        "We'll also practice using a new but similar dataloader function to what we've used before, `image_dataset_from_directory()` which is part of the `tf.keras.preprocessing` module.\n",
        "\n",
        "Finally, we'll also be practicing using the [`Keras Functional API`](https://keras.io/guides/functional_api/) for building deep learning models. The Functional API is a more flexible way to create models than the tf.keras.Sequential API."
      ],
      "metadata": {
        "id": "Vd5Z-IGcjkt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of the data of the 10 classes\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "id": "BiVTo1O0t8ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d197124-551b-451a-da7b-9173edac55b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-30 18:16:27--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 74.125.24.128, 142.250.4.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  52.6MB/s    in 3.1s    \n",
            "\n",
            "2022-09-30 18:16:31 (52.6 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the data\n",
        "unzip_data(\"/content/10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "aEqo5SJFlbQV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# walkthrough the directories\n",
        "walk_through_dir(\"/content/10_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "-L8KGh_nllqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c304f07e-2332-4234-956e-cd3203e7599c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/10_food_classes_10_percent: There are 2 directories and 0 files\n",
            "/content/10_food_classes_10_percent/train: There are 10 directories and 0 files\n",
            "/content/10_food_classes_10_percent/train/steak: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/pizza: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/ramen: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/hamburger: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/chicken_wings: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/fried_rice: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/grilled_salmon: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/sushi: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/chicken_curry: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/train/ice_cream: There are 0 directories and 75 files\n",
            "/content/10_food_classes_10_percent/test: There are 10 directories and 0 files\n",
            "/content/10_food_classes_10_percent/test/steak: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/pizza: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/ramen: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/hamburger: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/chicken_wings: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/fried_rice: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/grilled_salmon: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/sushi: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/chicken_curry: There are 0 directories and 250 files\n",
            "/content/10_food_classes_10_percent/test/ice_cream: There are 0 directories and 250 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test directories\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "id": "NTN786l7nipK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got some image data, we need a way of loading it into a TensorFlow compatible format.\n",
        "\n",
        "Previously we've used the `ImageDataGenerator` class. And while this works well and is still very commonly used, this time we're going to use the `image_data_from_directory` function.\n",
        "\n",
        "It works much the same way as `ImageDataGenerator`'s `flow_from_directory` method meaning your images need to be in the following file format:\n",
        "\n",
        "Example of file structure:\n",
        "10_food_classes_10_percent <- top level folder\n",
        "└───train <- training images \n",
        "│   │   │     \n",
        "│   └───pizza\n",
        "    \n",
        "│- - - - -  1008104.jpg'\n",
        "\n",
        "│- - - - -  1638227.jpg\n",
        " \n",
        "│- - - - -  ...      \n",
        "│   └───steak\n",
        "\n",
        "│- - - - -  1000205.jpg\n",
        "\n",
        "│- - - - -  1647351.jpg\n",
        "\n",
        "│- - - - -   ...\n",
        "      \n",
        "└───test <- testing images\n",
        "\n",
        "│   └───pizza\n",
        "\n",
        "│- - - - -  1001116.jpg\n",
        "\n",
        "│- - - - -  1507019.jpg\n",
        "\n",
        "│- - - - -  ...      \n",
        "\n",
        "│   └───steak\n",
        "\n",
        "│- - - - -  100274.jpg\n",
        "\n",
        "│- - - - -  1653815.jpg\n",
        "\n",
        "│- - - - -  ...   \n",
        "\n",
        "One of the main benefits of using `tf.keras.preprocessing.image_dataset_from_directory()` rather than `ImageDataGenerator` is that it creates a `tf.data.Dataset` object rather than a generator. The main advantage of this is the `tf.data.Dataset` API is much more efficient (faster) than the `ImageDataGenerator` API which is paramount for larger datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "z-DPeXrpoNtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data inputs\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\", # what type are the labels?\n",
        "                                                                            batch_size=BATCH_SIZE) # batch_size is 32 by default, this is generally a good number\n",
        "\n",
        "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           label_mode=\"categorical\",\n",
        "                                                                           batch_size=BATCH_SIZE)                                                                         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LjvGJP3oLGu",
        "outputId": "2244d916-fd5c-4d81-c2b1-00f314e97401"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like our dataloaders have found the correct number of images for each dataset.\n",
        "\n",
        "For now, the main parameters we're concerned about in the `image_dataset_from_directory()` function are:\n",
        "- `directory` - the filepath of the target directory we're loading images in from.\n",
        "- `image_size` - the target size of the images we're going to load in (height, width).\n",
        "- `batch_size` - the batch size of the images we're going to load in. For example if the batch_size is 32 (the default), batches of 32 images and labels at a time will be passed to the model."
      ],
      "metadata": {
        "id": "HVm-d7ymsWqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the training data datatype\n",
        "train_data_10_percent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAyUIAGusNfR",
        "outputId": "0d1ad34d-b33e-4fbe-ce4a-874f4c341ab4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above output:\n",
        "- `(None, 224, 224, 3)` refers to the tensor shape of our images where `None` is the batch size, `224` is the height (and width) and `3` is the color channel (red, green blue).\n",
        "- `(None, 10)` refers to the tensor shape of the labels where `None` is the batch size and `10` is the number of possible labels (the 10 different food classes).\n",
        "- Both image tensors and labels are of the datatype `tf.float32`.\n",
        "\n",
        "The `batch_size` is `None` due to it only being used during model training. You can think `None` as a placeholder waiting to be filled with the `batch_size` parameter from `image_dataset_from_directory()`.\n",
        "\n",
        "Another benefit of using `tf.data.Dataset` API are the associated methods which come with it.\n",
        "\n",
        "For example, if we want to find the name of the classes we were working with, we could use the `class_names` attribute."
      ],
      "metadata": {
        "id": "uEEfb85wvp1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the class names of our dataset\n",
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcbWYoTHvhka",
        "outputId": "54fcf7ea-64c7-435d-87bf-0b84211e1455"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See an example of batch of data\n",
        "train_data_10_percent.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrL4nUlOxFJ1",
        "outputId": "424f5ed4-13a2-43fd-b84c-97b55aba7c7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images)\n",
        "  print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbx2VKNXxMQ3",
        "outputId": "2080ff4c-4b5d-4815-aeaa-5fa624198c48"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[1.09438772e+01 9.94387722e+00 5.94387770e+00]\n",
            "   [9.76020336e+00 8.76020336e+00 4.76020384e+00]\n",
            "   [8.63775539e+00 7.63775492e+00 3.63775492e+00]\n",
            "   ...\n",
            "   [4.00000000e+00 4.00000000e+00 2.00000000e+00]\n",
            "   [3.00000000e+00 5.00000000e+00 4.00000000e+00]\n",
            "   [3.00000000e+00 5.00000000e+00 4.00000000e+00]]\n",
            "\n",
            "  [[8.07142830e+00 7.07142830e+00 3.07142830e+00]\n",
            "   [8.00510216e+00 7.00510216e+00 3.00510192e+00]\n",
            "   [7.00000000e+00 6.00000000e+00 2.00000000e+00]\n",
            "   ...\n",
            "   [4.00000000e+00 4.00000000e+00 2.00000000e+00]\n",
            "   [3.00000000e+00 5.00000000e+00 4.00000000e+00]\n",
            "   [3.00000000e+00 5.00000000e+00 4.00000000e+00]]\n",
            "\n",
            "  [[8.57142830e+00 7.78571415e+00 4.21428585e+00]\n",
            "   [8.57142830e+00 7.78571415e+00 4.21428585e+00]\n",
            "   [8.78571415e+00 8.00000000e+00 4.42857170e+00]\n",
            "   ...\n",
            "   [4.00000000e+00 4.00000000e+00 2.00000000e+00]\n",
            "   [3.00000000e+00 5.00000000e+00 4.00000000e+00]\n",
            "   [3.00000000e+00 5.00000000e+00 4.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[2.42132782e+02 2.36495087e+02 2.28352249e+02]\n",
            "   [2.45969498e+02 2.41127731e+02 2.32127747e+02]\n",
            "   [2.49357254e+02 2.43928726e+02 2.37500198e+02]\n",
            "   ...\n",
            "   [2.08117233e+02 2.09285583e+02 2.04285583e+02]\n",
            "   [2.17122238e+02 2.18122238e+02 2.13122238e+02]\n",
            "   [2.14719528e+02 2.15719528e+02 2.10719528e+02]]\n",
            "\n",
            "  [[2.53474518e+02 2.51525558e+02 2.47260254e+02]\n",
            "   [2.54137772e+02 2.53076553e+02 2.48280655e+02]\n",
            "   [2.53484711e+02 2.54071442e+02 2.49285721e+02]\n",
            "   ...\n",
            "   [1.99627548e+02 2.01627548e+02 1.96627548e+02]\n",
            "   [1.98341904e+02 2.00341904e+02 1.95341904e+02]\n",
            "   [2.06974365e+02 2.08974365e+02 2.03974365e+02]]\n",
            "\n",
            "  [[2.53928497e+02 2.53928497e+02 2.51928497e+02]\n",
            "   [2.53688736e+02 2.55000000e+02 2.52642822e+02]\n",
            "   [2.52857101e+02 2.54719360e+02 2.52010178e+02]\n",
            "   ...\n",
            "   [1.99005173e+02 2.01005173e+02 1.96005173e+02]\n",
            "   [1.99260223e+02 2.01260223e+02 1.96260223e+02]\n",
            "   [2.02056046e+02 2.04056046e+02 1.99056046e+02]]]\n",
            "\n",
            "\n",
            " [[[2.70714283e+01 2.40714283e+01 1.50714283e+01]\n",
            "   [2.50714283e+01 2.20714283e+01 1.30714283e+01]\n",
            "   [2.46428566e+01 2.16428566e+01 1.26428576e+01]\n",
            "   ...\n",
            "   [7.77092133e+01 6.49184036e+01 4.07091675e+01]\n",
            "   [9.05969849e+01 7.52398376e+01 5.15255547e+01]\n",
            "   [9.33571091e+01 7.79999619e+01 5.42856789e+01]]\n",
            "\n",
            "  [[2.46683674e+01 2.16683674e+01 1.26683674e+01]\n",
            "   [2.59948978e+01 2.29948978e+01 1.39948978e+01]\n",
            "   [2.48571415e+01 2.18571415e+01 1.28571424e+01]\n",
            "   ...\n",
            "   [4.68571396e+01 3.95714264e+01 2.14285698e+01]\n",
            "   [5.01479683e+01 4.27295799e+01 2.46530609e+01]\n",
            "   [5.04999237e+01 4.12142105e+01 2.40713558e+01]]\n",
            "\n",
            "  [[2.60000000e+01 2.30000000e+01 1.40000000e+01]\n",
            "   [2.48571434e+01 2.18571434e+01 1.28571424e+01]\n",
            "   [2.28316326e+01 1.98316326e+01 1.08316326e+01]\n",
            "   ...\n",
            "   [4.09540634e+01 3.69540634e+01 2.51683502e+01]\n",
            "   [4.11581650e+01 3.55867386e+01 2.38010235e+01]\n",
            "   [4.14336815e+01 3.58622513e+01 2.40765381e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.88602325e+02 1.86602325e+02 1.64030853e+02]\n",
            "   [1.85892975e+02 1.83892975e+02 1.61321503e+02]\n",
            "   [1.87729401e+02 1.85729401e+02 1.63157928e+02]\n",
            "   ...\n",
            "   [2.34214264e+02 2.49214264e+02 2.44214264e+02]\n",
            "   [2.34015305e+02 2.49015305e+02 2.44015305e+02]\n",
            "   [2.35709183e+02 2.50709183e+02 2.45709183e+02]]\n",
            "\n",
            "  [[1.91673553e+02 1.89673553e+02 1.64673553e+02]\n",
            "   [1.84841965e+02 1.82841965e+02 1.57841965e+02]\n",
            "   [1.74142929e+02 1.72142929e+02 1.47142929e+02]\n",
            "   ...\n",
            "   [2.33000000e+02 2.48000000e+02 2.43000000e+02]\n",
            "   [2.34142883e+02 2.49142883e+02 2.44142883e+02]\n",
            "   [2.36071442e+02 2.51071442e+02 2.46071442e+02]]\n",
            "\n",
            "  [[1.65626694e+02 1.61626694e+02 1.34626694e+02]\n",
            "   [1.83116653e+02 1.79116653e+02 1.52116653e+02]\n",
            "   [1.74876678e+02 1.70876678e+02 1.43876678e+02]\n",
            "   ...\n",
            "   [2.35142914e+02 2.50142914e+02 2.45142914e+02]\n",
            "   [2.36000000e+02 2.51000000e+02 2.46000000e+02]\n",
            "   [2.35872421e+02 2.50872421e+02 2.45872421e+02]]]\n",
            "\n",
            "\n",
            " [[[2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   ...\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]]\n",
            "\n",
            "  [[2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   ...\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]]\n",
            "\n",
            "  [[2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   ...\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]\n",
            "   [2.54000000e+02 2.54000000e+02 2.54000000e+02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[2.54421722e+02 2.54421722e+02 2.54421722e+02]\n",
            "   [2.54520584e+02 2.54520584e+02 2.54520584e+02]\n",
            "   [2.53188248e+02 2.53188248e+02 2.53188248e+02]\n",
            "   ...\n",
            "   [2.50447601e+02 2.50447601e+02 2.50447601e+02]\n",
            "   [2.52686172e+02 2.52686172e+02 2.52686172e+02]\n",
            "   [2.53694305e+02 2.53694305e+02 2.53694305e+02]]\n",
            "\n",
            "  [[2.53052780e+02 2.53052780e+02 2.53052780e+02]\n",
            "   [2.54455017e+02 2.54455017e+02 2.54455017e+02]\n",
            "   [2.55000000e+02 2.55000000e+02 2.55000000e+02]\n",
            "   ...\n",
            "   [2.54551331e+02 2.54551331e+02 2.54551331e+02]\n",
            "   [2.54272491e+02 2.54272491e+02 2.54272491e+02]\n",
            "   [2.55000000e+02 2.55000000e+02 2.55000000e+02]]\n",
            "\n",
            "  [[2.53205566e+02 2.53205566e+02 2.53205566e+02]\n",
            "   [2.53489075e+02 2.53489075e+02 2.53489075e+02]\n",
            "   [2.52770493e+02 2.52770493e+02 2.52770493e+02]\n",
            "   ...\n",
            "   [2.53466400e+02 2.53466400e+02 2.53466400e+02]\n",
            "   [2.54565491e+02 2.54565491e+02 2.54565491e+02]\n",
            "   [2.52807922e+02 2.52807922e+02 2.52807922e+02]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[7.44454727e+01 5.54454727e+01 2.32187500e+01]\n",
            "   [7.20966187e+01 5.34241066e+01 1.94416447e+01]\n",
            "   [8.41734695e+01 6.61734695e+01 2.80223198e+01]\n",
            "   ...\n",
            "   [1.14333401e+01 6.43334055e+00 2.43334031e+00]\n",
            "   [1.03064327e+01 5.30643272e+00 1.30643284e+00]\n",
            "   [1.00580359e+01 5.05803585e+00 1.05803585e+00]]\n",
            "\n",
            "  [[7.52471313e+01 5.52471313e+01 2.08453445e+01]\n",
            "   [7.42598877e+01 5.42598877e+01 1.91438122e+01]\n",
            "   [8.27920990e+01 6.30519791e+01 2.52474499e+01]\n",
            "   ...\n",
            "   [8.78573608e+00 4.78573608e+00 1.78573608e+00]\n",
            "   [1.09378176e+01 6.93781805e+00 3.93781805e+00]\n",
            "   [1.04106789e+01 6.41067886e+00 3.43140793e+00]]\n",
            "\n",
            "  [[7.16881332e+01 5.01613541e+01 1.23488522e+01]\n",
            "   [7.64177322e+01 5.48909454e+01 1.63641586e+01]\n",
            "   [8.72863541e+01 6.64869232e+01 2.54585457e+01]\n",
            "   ...\n",
            "   [5.73216438e+00 4.02234316e+00 4.22517776e-01]\n",
            "   [6.87498665e+00 5.16516542e+00 1.40177250e+00]\n",
            "   [4.35264349e+00 2.64282227e+00 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.01370224e+02 7.43702240e+01 3.37022614e+00]\n",
            "   [1.02351700e+02 7.53516998e+01 4.42312765e+00]\n",
            "   [1.01344063e+02 7.49869156e+01 3.77263165e+00]\n",
            "   ...\n",
            "   [7.63366699e-01 2.71266460e+00 0.00000000e+00]\n",
            "   [9.45463836e-01 2.94546390e+00 0.00000000e+00]\n",
            "   [2.36633301e-01 1.96397567e+00 0.00000000e+00]]\n",
            "\n",
            "  [[1.05074379e+02 7.80743790e+01 7.07437754e+00]\n",
            "   [1.06285500e+02 7.92854996e+01 8.28964806e+00]\n",
            "   [1.02013412e+02 7.56562729e+01 4.44198704e+00]\n",
            "   ...\n",
            "   [0.00000000e+00 1.78573608e+00 0.00000000e+00]\n",
            "   [1.00000000e+00 3.00000000e+00 0.00000000e+00]\n",
            "   [1.00000000e+00 3.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[1.02407181e+02 7.64071808e+01 2.40718317e+00]\n",
            "   [1.10101105e+02 8.41011047e+01 1.01011028e+01]\n",
            "   [9.49147873e+01 6.93433609e+01 1.51140586e-01]\n",
            "   ...\n",
            "   [9.24437463e-01 2.92443752e+00 0.00000000e+00]\n",
            "   [3.27466428e-01 2.32746649e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.22669840e+00 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[6.14948959e+01 5.24948959e+01 4.54948959e+01]\n",
            "   [3.69846916e+01 2.79846916e+01 2.09846916e+01]\n",
            "   [2.42040806e+01 1.52040806e+01 8.20408058e+00]\n",
            "   ...\n",
            "   [1.95714073e+01 1.35714064e+01 1.55714064e+01]\n",
            "   [1.90000000e+01 1.30000000e+01 1.50000000e+01]\n",
            "   [2.00000000e+01 1.40000000e+01 1.60000000e+01]]\n",
            "\n",
            "  [[2.52448959e+01 1.62448959e+01 9.24489594e+00]\n",
            "   [2.68622456e+01 1.78622456e+01 1.08622456e+01]\n",
            "   [2.39132652e+01 1.49132652e+01 7.91326571e+00]\n",
            "   ...\n",
            "   [1.89285717e+01 1.29285717e+01 1.49285717e+01]\n",
            "   [1.90663395e+01 1.30663385e+01 1.50663385e+01]\n",
            "   [2.00255127e+01 1.40255127e+01 1.60255127e+01]]\n",
            "\n",
            "  [[2.32142868e+01 1.42142859e+01 7.64285755e+00]\n",
            "   [2.22857132e+01 1.32857141e+01 6.71428585e+00]\n",
            "   [2.26428585e+01 1.36428576e+01 7.07142925e+00]\n",
            "   ...\n",
            "   [2.07857132e+01 1.47857141e+01 1.67857132e+01]\n",
            "   [2.09285583e+01 1.49285583e+01 1.69285583e+01]\n",
            "   [1.90000000e+01 1.30000000e+01 1.50000000e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.58510269e+02 1.61081741e+02 1.66505249e+02]\n",
            "   [1.40612335e+02 1.39923538e+02 1.44326660e+02]\n",
            "   [1.34785568e+02 1.30356995e+02 1.31571274e+02]\n",
            "   ...\n",
            "   [1.79954880e+02 1.84863052e+02 2.03174362e+02]\n",
            "   [1.81668915e+02 1.79041321e+02 1.97714783e+02]\n",
            "   [2.05561157e+02 2.01362000e+02 2.18856918e+02]]\n",
            "\n",
            "  [[1.80178909e+02 1.83178909e+02 1.90985046e+02]\n",
            "   [1.48454193e+02 1.49316422e+02 1.54739929e+02]\n",
            "   [1.31398026e+02 1.28755173e+02 1.32081726e+02]\n",
            "   ...\n",
            "   [1.84581924e+02 1.78892975e+02 1.90923523e+02]\n",
            "   [1.94448318e+02 1.84029877e+02 1.92514481e+02]\n",
            "   [1.78357254e+02 1.67357254e+02 1.71928482e+02]]\n",
            "\n",
            "  [[2.29046234e+02 2.32632980e+02 2.41913559e+02]\n",
            "   [1.79520996e+02 1.79520996e+02 1.87663849e+02]\n",
            "   [1.48837021e+02 1.46474792e+02 1.51413589e+02]\n",
            "   ...\n",
            "   [1.71059097e+02 1.45849640e+02 1.54706696e+02]\n",
            "   [1.23300056e+02 1.04274567e+02 9.86774292e+01]\n",
            "   [8.23654556e+01 7.17941666e+01 5.45795708e+01]]]\n",
            "\n",
            "\n",
            " [[[2.51581631e+01 1.41581640e+01 1.01581640e+01]\n",
            "   [2.82602043e+01 1.72602043e+01 1.52602043e+01]\n",
            "   [2.97857132e+01 1.57857141e+01 1.47857141e+01]\n",
            "   ...\n",
            "   [3.26223717e+01 2.65458488e+01 3.07754173e+01]\n",
            "   [2.90203991e+01 2.00203991e+01 2.16836548e+01]\n",
            "   [3.04183178e+01 2.24183178e+01 2.04183178e+01]]\n",
            "\n",
            "  [[3.19030628e+01 1.79030609e+01 1.49030619e+01]\n",
            "   [2.80000000e+01 1.40000000e+01 1.10000000e+01]\n",
            "   [3.07704067e+01 1.67704067e+01 1.57704077e+01]\n",
            "   ...\n",
            "   [1.19178078e+02 1.15106644e+02 1.16320930e+02]\n",
            "   [6.52752991e+01 5.92752953e+01 5.92752953e+01]\n",
            "   [3.42291985e+01 2.92291985e+01 2.62291985e+01]]\n",
            "\n",
            "  [[3.31326561e+01 1.89183674e+01 1.59183674e+01]\n",
            "   [2.96989803e+01 1.54846935e+01 1.24846935e+01]\n",
            "   [3.12142868e+01 1.66632652e+01 1.41683674e+01]\n",
            "   ...\n",
            "   [2.23821198e+02 2.20969116e+02 2.19157898e+02]\n",
            "   [1.88035477e+02 1.84678329e+02 1.83035477e+02]\n",
            "   [1.36667511e+02 1.33310364e+02 1.30096085e+02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.28622589e+01 1.08622589e+01 1.34337311e+01]\n",
            "   [1.10561237e+01 9.05612373e+00 1.16275959e+01]\n",
            "   [1.44285717e+01 9.47446346e+00 1.28316717e+01]\n",
            "   ...\n",
            "   [8.40750732e+01 6.86465454e+01 6.32180214e+01]\n",
            "   [3.84786110e+01 2.36674786e+01 2.04379082e+01]\n",
            "   [2.17550201e+01 9.89796543e+00 6.96934605e+00]]\n",
            "\n",
            "  [[1.29285583e+01 1.09285583e+01 1.39285583e+01]\n",
            "   [1.20000000e+01 1.00000000e+01 1.30000000e+01]\n",
            "   [1.54285717e+01 8.78571415e+00 1.30000000e+01]\n",
            "   ...\n",
            "   [2.19080334e+01 1.18213453e+01 9.42343235e+00]\n",
            "   [2.24284668e+01 1.47805710e+01 1.28520126e+01]\n",
            "   [1.74795322e+01 1.20306282e+01 1.09386873e+01]]\n",
            "\n",
            "  [[9.87243652e+00 9.87243652e+00 1.18724365e+01]\n",
            "   [1.20000000e+01 1.00000000e+01 1.30000000e+01]\n",
            "   [1.64285717e+01 9.78571415e+00 1.40000000e+01]\n",
            "   ...\n",
            "   [1.68929386e+01 1.11990891e+01 8.96450138e+00]\n",
            "   [1.75663624e+01 1.43725662e+01 1.53725662e+01]\n",
            "   [1.47293577e+01 1.39029169e+01 1.43161373e+01]]]], shape=(32, 224, 224, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the image arrays come out as tensors of pixel values where as the labels come out as one-hot encodings (e.g. `[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]` for `hamburger`)"
      ],
      "metadata": {
        "id": "_cbnmJ4Gx3cY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Building a transfer learning model using the Keras Functional API\n",
        "\n",
        "Let's build a model.\n",
        "\n",
        "To do so we're going to be using the `tf.keras.applications` module as it contains a series of already trained (on ImageNet) computer vision models as well as the Keras Functional API to construct our model.\n",
        "\n",
        "We're going to go through the following steps:\n",
        "\n",
        "1. Instantiate a pre-trained base model object by choosing a target model such as `EfficientNetB0` from `tf.keras.applications`, setting the `include_top` parameter to `False` (we do this because we're going to create our own top, which are the output layers for the model).\n",
        "2. Set the base model's `trainable` attribute to `False` to freeze all the weights in the pre-trained model.\n",
        "3. Define an input layer for our model, for example, what shape of data should our model expect?\n",
        "4. [Optional] Normalize the inputs to our model if it requires. Some computer vision models such as `ResNetV250` require their inputs to be between 0 & 1.\n",
        "> **Note :** As of writing, the `EfficientNetB0` models in `tf.keras.applications` module do not require images to be normalized on input, where as many of the other models do. \n",
        "\n",
        "5. Pass the inputs to the base model.\n",
        "6. Pool the outputs of the base model into a shape compatible with the output activation layer (turn base model output tensors into same shape as label tensors). This can be done using `tf.keras.layers.GlobalAveragePooling2D()` or `tf.keras.layers.GlobalMaxPooling2D()` though the former is more common in practice).\n",
        "7. Create an output activation layer using `tf.keras.layers.Dense()` with the appropriate activation function and number of neurons.\n",
        "8. Combine the inputs and outputs layer into a model using `tf.keras.Model()`\n",
        "9. Compile the model using the appropriate loss function and choose of optimizer.\n",
        "10. Fit the model for desired number of epochs and with necessary callbacks."
      ],
      "metadata": {
        "id": "DPAvgDhUy5-w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-wuFN02QxWAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}