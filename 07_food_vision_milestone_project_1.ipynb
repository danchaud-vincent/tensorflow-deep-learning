{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLfqpgZpqeKpt8HpTCqDot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danchaud-vincent/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 07 - Food vision milestone Project 1"
      ],
      "metadata": {
        "id": "1KhtQ8diX6qU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous chapter (**transfer learning part 3: scaling up**) we build Food Vision mini: a transfer learning model which beat the original results of the [Food 101 paper](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) with only 10% of the data.\n",
        "\n",
        "Now, what would happen if we used all the data ?\n",
        "\n",
        "Well, that's we're going to find out in this notebook!\n",
        "\n",
        "We're going to be building Food Vision Big, using all of the data from the Food101 dataset.\n",
        "\n",
        "This time **we've got the goal of beating [DeepFood](https://www.researchgate.net/publication/304163308_DeepFood_Deep_Learning-Based_Food_Image_Recognition_for_Computer-Aided_Dietary_Assessment), a 2016 paper which used a Convolutional Neural Network trained for 2-3 days to achieve 77.4% top-1 accuracy.\n",
        "\n",
        "> **Note :** **Top-1 accuracy** means \"accuracy for the top softmax activation value output by the model\" (because softmax outputs a value for every class, but top-1 means only the highest one is evaluated). **Top-5 accuracy** means \"accuracy for the top 5 softmax activation values output by the model\", in other words, did the true label appear in the top 5 activation values? Top-5 accuracy scores are usually noticeably higher than top-1.\n",
        "\n",
        "\n",
        "<table>\n",
        "    <thead>\n",
        "        <tr>\n",
        "            <th></th>\n",
        "            <th>üçîüëÅ Food Vision Big‚Ñ¢</th>\n",
        "            <th>üçîüëÅ Food Vision mini</th>\n",
        "        </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td>Dataset source</td>\n",
        "            <td>TensorFlow Datasets</td>\n",
        "            <td>Preprocessed download from Kaggle</td>\t\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>Train data</td>\n",
        "            <td>75,750 images</td>\n",
        "            <td>7,575 images</td>\t\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>Test data</td>\n",
        "            <td>25,250 images</td>\n",
        "            <td>25,250 images</td>\t\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>Mixed precision</td>\n",
        "            <td>Yes</td>\n",
        "            <td>No</td>\t\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>Data loading</td>\n",
        "            <td>Perform tf.data API</td>\n",
        "            <td>TensorFlow pre-built function</td>\t\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>Target results</td>\n",
        "            <td>77,4% top-1 accuracy</td>\n",
        "            <td>50,76% top-1 accuracy</td>\t\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\n",
        "Alongside attempting to beat the DeepFood paper, we're going to learn about two methods to significantly improve the speed of our model training:\n",
        "1. Prefetching\n",
        "2. Mixed precision training"
      ],
      "metadata": {
        "id": "Yvzx6LoDar4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check GPU\n",
        "\n",
        "For this notebook, we're going to be doing something different.\n",
        "\n",
        "We're going to be using mixed precision training.\n",
        "\n",
        "Mixed precision training was introduced in Tensorflow 2.4.0.\n",
        "\n",
        "What does **mixed precision training** do?\n",
        "\n",
        "Mixed precision training uses a combination of single precision (float 32) and half-precision (float16) data types to speed up model training (up 3x on modern GPUs).\n",
        "\n",
        "We'll talk about this more later on but in the meantime you can read the [Tensorflow documention on mixed precision](https://www.tensorflow.org/guide/mixed_precision) for more details.\n",
        "\n",
        "For now, before we can move forward if we want to use mixed precision training we need to make sure the GPU powering our Google Colab instance is compatible.\n",
        "\n",
        "For mixed precision training to work, you need to access to a GPU with a compute compatibility score of 7.0+.\n",
        "\n",
        "Google Colab offers P100, K80 and T4 GPUs, however, **the P100 and K80 are not compatible with mixed precision training.**\n",
        "\n",
        "Therefore before we proceed we need to make sure we have **access to a Tesla T4 GPU in ou google Colab instance.**\n",
        "\n",
        "If you're not using Google Colab, you can find a list of various Nvidia GPU compute capabilities on Nvidia's developer website."
      ],
      "metadata": {
        "id": "gMkyb0-Kd6uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If using Google Colab, this should output \"Tesla T4\" otherwise, \n",
        "# you won't be able to use mixed precision training\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Eesun7cBUo",
        "outputId": "6cf8f48f-a168-4d9a-be7f-22002e142f61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-277ec80a-f5cf-b3cf-ce2c-3e2a412c6e5b)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check TensorFlow version (should be 2.4.0+)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZD1h6UcfMnq",
        "outputId": "affd7dc7-07f7-4171-a3de-61c447ce51a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Helper functions"
      ],
      "metadata": {
        "id": "4OMXHkj6fXwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've created a series of helper function throughout the previous notebooks in the course. Instead of rewriting them (tedious), we'll import the `helper_functions.py` file from the Github repo."
      ],
      "metadata": {
        "id": "4kqlp2Arf51k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper functions file\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"helper_functions.py\"):\n",
        "  !wget https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/utils/helper_functions.py\n",
        "else:\n",
        "  print(\"[INFO] 'helper_functions.py' already exists, skipping download.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAbLt0BXfUlz",
        "outputId": "0dae38c2-17af-4a0b-d218-588e07c7fbbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-19 15:30:20--  https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/utils/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4405 (4.3K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py‚Äô\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   4.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-19 15:30:20 (68.2 MB/s) - ‚Äòhelper_functions.py‚Äô saved [4405/4405]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import series of helper functions for the notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "vmqz6nIBgX6k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use TensorFlow Datasets to Download Data"
      ],
      "metadata": {
        "id": "v-MTBkEeg-Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vV1_whF4g9J7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}