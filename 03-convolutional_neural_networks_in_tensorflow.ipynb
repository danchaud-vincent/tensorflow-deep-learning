{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Convolutional Neural Networks And Computer Vision with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the prievious notebook we've covered the basics of TensorFlow and built some models to work across different problems.\n",
    "\n",
    "Now we're going to get specific and see how a special kind of neural network, **Convolutional neural networks (CNNs)** can be used for computer vision (detecting patterns in visual data).\n",
    "\n",
    "> **Note:** In deep learning, many different kinds of model architectures can be used for different problems. For example, you could use a convolutional neural network for making predictions on image data and/or text data. However, in practice some architectures typically work better than others.\n",
    "\n",
    "For example, you might want to:\n",
    "- Classify whether a picture of fodd contains pizza üçï or steak ü•©\n",
    "- Detect whether or not an object appears in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we're going to cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we're going to go through the follow with TensorFlow:\n",
    "\n",
    "- Getting a dataset to work with\n",
    "- Architecture of a convolutional neural network\n",
    "- A quick end-to-end example\n",
    "- Steps in modelling for binary image classification with CNNs\n",
    "    - Becoming one with the data\n",
    "    - Preparing data for modelling\n",
    "    - Creating a CNN model\n",
    "    - Fitting a model\n",
    "    - Evaluating a model\n",
    "    - Improving a model\n",
    "    - Making a prediction with a trained model\n",
    "- Steps in modelling for multi-class image classification with CNNs\n",
    "    - Same as above (but this time with a different dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A (typical) architecture of a convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks are no different to other kinds of deep learning neural networks in the fact they can be created in many different ways. Whate you see below are some components you'd expect to find in a traditional CNN.\n",
    "\n",
    "Components of a convolutional neural network:\n",
    "\n",
    "| **Hyperparameter/Layer type** | **What does it do?** | **Typical values** |\n",
    "| ----- | ----- | ----- |\n",
    "| Input images(s) | Target images you'd like to discover patterns in | Whatever you can take a photo (or video) of |\n",
    "| Input layer | Takes in target images and preprocesses them for further layers | `input_shape = [batch_size,image_height, image_width, color_channels]` |\n",
    "| Convolution layer | Extracts/learns the most important features from target images | Multiple, can create with `tf.Keras.layers.ConvXD` (X can be multiple values) |\n",
    "| Hidden activation | Adds non-linearity to learned features (non-straight lines) | Usually ReLU (`tf.keras.activations.relu`) |\n",
    "| Pooling layer | Reduces the dimensionality of learned image features | Average (`tf.keras.layers.AvgPool2D`) or Max (`tf.keras.layers.MaxPool2D`) |\n",
    "| Fully connected layer | Further refines learned features from convolutional layers | `tf.keras.layers.Dense` |\n",
    "| Output layer | Takes learned features and outputs them in shape of target labels | `output_shape = [number_of_classes]` (e.g. 3 for pizza, steak or sushi) |\n",
    "| Output activation | Adds non-linearities to output layer | `tf.keras.activations.sigmoid` (binary classification) or `tf.keras.activations.softmax` |\n",
    "\n",
    "Example stack together : \n",
    "\n",
    "<center><img src = \"images/03-simple-convnet.png\" width = 800px></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because convolutional neural networks work so well with images, to learn more about them, we're going to start with a dataset of images.\n",
    "\n",
    "The images we're going to work with are from the [Food-101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/), a collection of 101 different categories of 101,000 (1000 images per category) real-world images of food dishes.\n",
    "\n",
    "To begin, we're only going to use two of the categories, pizza üçï and steak ü•© and build a binary classifier.\n",
    "\n",
    "> üîë **Note:** To prepare the data we're using, preprocessing steps such as, moving the images into different subset folders, have been done. To see these preprocessing steps check out the preprocessing notebook.\n",
    "\n",
    "\n",
    "We'll download the `pizza_steak` subset .zip file and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=c6784904cfb2b23c20f87886696cae0017dbecfc6b8da4f9531f4880c0537041\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\bd\\a8\\c3\\3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "# Install wget\n",
    "# !pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wget' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a163d2b4875a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/dataset\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mwget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wget' is not defined"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Download zip file of pizza_steak images\n",
    "path = \"data/dataset\"\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip \"\n",
    "wget.download(url, out = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
