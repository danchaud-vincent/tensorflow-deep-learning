{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuhdrPIs3HvwrWW/LGZm40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danchaud-vincent/tensorflow-deep-learning/blob/main/05_Transfer_learning_in_tensorflow_part2_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 05. Transfer Learning with TensorFlow Part 2: Fine-tuning"
      ],
      "metadata": {
        "id": "oKfQArbiYHeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food Vision project than building our own models (even with less data).\n",
        "\n",
        "Now we're going to cover another type of transfer learning: fine-tuning.\n",
        "\n",
        "In **fine-tuning transfer learning** the pre-trained model weights from another model are unfrozen and tweaked during to better suit your own data.\n",
        "\n",
        "For feature extraction transfer learning, you may only train the top 1-3 layers of a pre-trained model with your own data, in fine-tuning transfer learning, you might train 1-3+ of pre-trained model.\n",
        "\n",
        "![](https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/images/05-transfer-learning-feature-extraction-vs-fine-tuning.png)"
      ],
      "metadata": {
        "id": "ezI2AdvMYFI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What we're going to cover\n",
        "\n",
        "We're going to go through the follow with TensorFlow:\n",
        "- Introduce fine-tuning, a type of transfer learning to modify a pre-trained model to be more suited to your data.\n",
        "- Using the Keras Functional API (a different way to build models in Keras)\n",
        "- Using a smaller dataset to experiment faster (e.g. 1-10% of training samples of 10 classes of food)\n",
        "- Data augmentation (how to make your training dataset more diverse without adding more data)\n",
        "- Running a series of modelling experiments on our Food Vision data:\n",
        "  - Model 0: a transfer learning model using Keras Functional API\n",
        "  - Model 1: a feature extraction transfer learning model on 1% of the data with data augmentation\n",
        "  - Model 2 : a feature extraction transfer learning model on 10 % of the data with data augmentation\n",
        "  - Model 3: a fine-tuned transfer learning model on 10% of the data\n",
        "  - Model 4: a fine-tuned transfer learning model on 100% of the data\n",
        "- Introduce the ModelCheckpoint callback to save intermediate training results\n",
        "- Compare model experiments results using TensorBoard"
      ],
      "metadata": {
        "id": "dsqKUaq6jTdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a GPU?\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQaOixQWkW0Y",
        "outputId": "c36de87d-1a3b-4feb-8642-421adf7b9b1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 29 18:46:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions\n",
        "\n",
        "Throughout your machine learning experiments, you'll likely come accross snippets of code you want to use over and over again.\n",
        "\n",
        "For example, a plotting function which plots a model's `history` object (see `plot_loss_curves()` below).\n",
        "\n",
        "You could recreate these functions over and over again. But as you might have guessed, rewritting the same functions becomes tedious.\n",
        "\n",
        "One of the solutions is to store them in a helper functions script such as `helper_functions.py`. And then import the necessary functionality when you need it.\n",
        "\n",
        "\n",
        "Let's see what this looks like."
      ],
      "metadata": {
        "id": "M0HG8i19jTUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from course GitHub\n",
        "!wget https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/utils/helper_functions.py "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BmHk2qUtmve",
        "outputId": "f698d36c-c2ad-4ea3-bb84-4c5c6e9f1b04"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-29 19:33:55--  https://raw.githubusercontent.com/danchaud-vincent/tensorflow-deep-learning/main/utils/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2622 (2.6K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "helper_functions.py 100%[===================>]   2.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-29 19:33:55 (50.4 MB/s) - ‘helper_functions.py.1’ saved [2622/2622]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import Helper functions we're going to use\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, walk_through_dir"
      ],
      "metadata": {
        "id": "gQnBafFPtwpi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BiVTo1O0t8ak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}