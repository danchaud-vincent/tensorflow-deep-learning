{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Neural Network Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Content of this notebook :**\n",
    "- Architecture of a regression model\n",
    "- Input shapes and output shapes\n",
    "    - `X`: features/data (inputs)\n",
    "    - `y`: labels (outputs)\n",
    "- Creating custom data to view and fit\n",
    "- Steps in modelling\n",
    "    - Creating a model\n",
    "    - Compiling a model\n",
    "        - Defining a loss function\n",
    "        - Setting up an optimizer\n",
    "        - Creating evaluation metrics\n",
    "    - Fitting a model (getting it to find patterns in our data)\n",
    "- Evaluating a model\n",
    "    - Visualizing the model \n",
    "    - Looking at training curves\n",
    "    - Compare predictions to ground truth\n",
    "- Saving a model\n",
    "- Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorfow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import numpy \n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many definitions for a regression problem but in our case, we're going to simplify it to be: predicting a number.\n",
    "\n",
    "For example, we might want to:\n",
    "- Predict the selling price of houses given information about them (such as number of rooms, size, number of bathrooms...).\n",
    "- Predict coordinates of a bounding box of an item in an image.\n",
    "- Predict the cost of medical insurance for an individual given their demographics (age, sex, gender, race)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical architecture of a regression neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word typical is on purpose. Why?\n",
    "\n",
    "Because there are many different ways to write neural networks. But the following is a generic setup for ingesting a collection of numbers, finding patterns in them and then outputing some kind of target number.\n",
    "\n",
    "| **Hyperparameter** | **Typical Value** |\n",
    "| --- | --- |\n",
    "| Input layer shape | Same shape as number of features (e.g. 3 for #bedrooms, #bathrooms, #car spaces in housing price prediction) |\n",
    "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |\n",
    "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
    "| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |\n",
    "| Hidden activation | Usually ReLU (rectified linear unit) |\n",
    "| Output activation | None, ReLU, logistic/tanh |\n",
    "| Loss function | MSE (mean squar error) or MAE (mean absolute error) ... |\n",
    "| Optimizer | SGD (stochastic gradient descent), Adam ... |\n",
    "\n",
    "***Table 1:*** *Typical architecture of a regression network.* ***Source:*** *Adapted from page 293 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aurélien Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*\n",
    "\n",
    "> **Note**: A **hyperparamter** in machine learning is something a data analyst or developer can set themselves, where as a **parameter** usually describes something a model learns on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data to view and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're working on a **regression problem** (predicting a number) let's create some linear data to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f07de6eb50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any modelling, can we calculate the pattern between `X` and `y` ?\n",
    "\n",
    "For example, based on this data what the `y` value if `X` is 17.0? Or if `X` is -10.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression input shapes and output shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important concepts when working with neural networks are the input and output shapes.\n",
    "\n",
    "- The **input shape** is the shape of your data that goes into the model.\n",
    "- The **output shape** is the shape of your data we want to come out of the model.\n",
    "\n",
    "Neural networks accept numbers and output numbers. These numbers are typically represented as tensors (or arrays).\n",
    "\n",
    "Before we created data using NumPy arrays, but we could do the same with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_info = tf.constant([\"bedroom\",\"bathroom\",\"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f07df94550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create features (using tensors)\n",
    "X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels (using tensors)\n",
    "y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# visualize it\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here will be to use `X` to predict `y`. So our **input** will be `X` and our **output** will be `y`.\n",
    "\n",
    "What is the shape of our input and output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a single example of X\n",
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=-7.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single example of our dataset\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is only 2 small lists of numbers, so each example is a scalar with a rank 0.\n",
    "\n",
    "In our case, we're trying to build a model to predict the pattern between `X[0]` equalling `-7.0` and `y[0]` equalling `-3.0`. We are trying to use one X value to predict one y value.\n",
    "\n",
    "<center><img src=\"images/01-input-and-output-shapes-housing-prices.png\" width=600px></center>\n",
    "\n",
    "*If you were working on building a machine learning algorithm for predicting housing prices, your inputs may be number of bedrooms, number of bathrooms and number of garages, giving you an input shape of 3 (3 different features). And since you're trying to predict the price of the house, your output shape would be 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n",
    "\n",
    "1. **Creating a model** - piece together the layers of a neural network yourself (using the Functional or Sequential API) or import a previously built model (known as transfer learninng).\n",
    "2. **Compiling a model** - defining how a model performance should be measured (loss/metrics) as well as defining how it should improve (optimizer).\n",
    "3 **Fitting a model** - letting the model try to find patterns in the data (how does `X` get to `y`).\n",
    "\n",
    "Let's see these in action using the `Keras Sequential API` to build a model for our regression data.\n",
    "\n",
    "> **Note**: if you're using TensorFlow 2.7.0+, the `fit()` function no longer upscales input data to go from `(batch_size,)` to `(batch_size,1)`. To fix this, we need to expand the dimension of input data using `tf.expand_dims(input_data,axis=-1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f07f46fdc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae -> Mean Absolute error\n",
    "              optimizer = tf.keras.optimizers.SGD(), # SQG is short for stochastic gradient descent\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f07f5b3580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other way to write the model\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using the model\n",
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't go very well for the prediction. IT should've output something close to 27.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we improve the model?\n",
    "\n",
    "To improve the model, we alter almost every part of the 3 steps we went through before.\n",
    "\n",
    "1. **Creating a model** - Here you might want to add more layers, increase the number of hidden units within each layer, change the activation functions of each layer.\n",
    "2. **Compiling a model** - you might want te choose optimization function or perhaps change the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - perhaps you could fit a model for more **epochs** or on more data.\n",
    "\n",
    "<center><img src=\"images/02-improving-a-model-from-model-perspective.png\" width=650px></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.9748 - mae: 10.9748\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8423 - mae: 10.8423\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.7098 - mae: 10.7098\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.5773 - mae: 10.5773\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.4448 - mae: 10.4448\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.3123 - mae: 10.3123\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.1798 - mae: 10.1798\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.0473 - mae: 10.0473\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.9148 - mae: 9.9148\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7823 - mae: 9.7823\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.6498 - mae: 9.6498\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5173 - mae: 9.5173\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.3848 - mae: 9.3848\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.2523 - mae: 9.2523\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.1198 - mae: 9.1198\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.9873 - mae: 8.9873\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.8548 - mae: 8.8548\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.7223 - mae: 8.7223\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.5898 - mae: 8.5898\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.4573 - mae: 8.4573\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3248 - mae: 8.3248\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.1923 - mae: 8.1923\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.0598 - mae: 8.0598\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9273 - mae: 7.9273\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.7948 - mae: 7.7948\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.6623 - mae: 7.6623\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.5298 - mae: 7.5298\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3973 - mae: 7.3973\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2648 - mae: 7.2648\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1963 - mae: 7.1963\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1738 - mae: 7.1738\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1063 - mae: 7.1063\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8869 - mae: 6.8869\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8813 - mae: 6.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f07f5aa2b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more epochs to our model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice the loss value decrease from before (and keep decreasing as the number of epochs get higher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.158512]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a new prediction with the new model\n",
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is much better. Now we need to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice : Try other changes to improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 12.3203 - mae: 12.3203\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1611 - mae: 11.1611\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9503 - mae: 9.9503\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6481 - mae: 8.6481\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2624 - mae: 7.2624\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2141 - mae: 7.2141\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1656 - mae: 7.1656\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1167 - mae: 7.1167\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0674 - mae: 7.0674\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0178 - mae: 7.0178\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9677 - mae: 6.9677\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9170 - mae: 6.9170\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8658 - mae: 6.8658\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8139 - mae: 6.8139\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7614 - mae: 6.7614\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7081 - mae: 6.7081\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6540 - mae: 6.6540\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5990 - mae: 6.5990\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5431 - mae: 6.5431\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5327 - mae: 6.5327\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0231 - mae: 7.0231\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7256 - mae: 6.7256\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.5607 - mae: 6.5607\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9293 - mae: 6.9293\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2442 - mae: 6.2442\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1835 - mae: 6.1835\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.1213 - mae: 6.1213\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0576 - mae: 6.0576\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.9924 - mae: 5.9924\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9254 - mae: 5.9254\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9162 - mae: 5.9162\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4863 - mae: 6.4863\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1402 - mae: 6.1402\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.9392 - mae: 5.9392\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4679 - mae: 6.4679\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4358 - mae: 6.4358\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7940 - mae: 5.7940\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8658 - mae: 5.8658\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0780 - mae: 6.0780\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3482 - mae: 6.3482\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4601 - mae: 5.4601\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7510 - mae: 5.7510\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.7252 - mae: 5.7252\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2233 - mae: 6.2233\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.1320 - mae: 5.1320\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.5940 - mae: 5.5940\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.4024 - mae: 5.4024\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0601 - mae: 6.0601\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8035 - mae: 4.8035\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.3931 - mae: 5.3931\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.1029 - mae: 5.1029\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.8570 - mae: 5.8570\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4676 - mae: 4.4676\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.1457 - mae: 5.1457\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.8200 - mae: 4.8200\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.6116 - mae: 5.6116\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.1171 - mae: 4.1171\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8485 - mae: 4.8485\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.5472 - mae: 4.5472\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.3208 - mae: 5.3208\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7438 - mae: 3.7438\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.4968 - mae: 4.4968\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2773 - mae: 4.2773\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.9805 - mae: 4.9805\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3383 - mae: 3.3383\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0848 - mae: 4.0848\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.0027 - mae: 4.0027\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5859 - mae: 4.5859\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8920 - mae: 2.8920\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0751 - mae: 5.0751\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3982 - mae: 2.3982\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6689 - mae: 5.6689\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0217 - mae: 4.0217\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5207 - mae: 2.5207\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8024 - mae: 4.8024\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9651 - mae: 2.9651\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.6898 - mae: 5.6898\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.8426 - mae: 2.8426\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5565 - mae: 5.5565\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7261 - mae: 2.7261\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.4362 - mae: 5.4362\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.6366 - mae: 2.6366\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0203 - mae: 4.0203\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1705 - mae: 3.1705\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7997 - mae: 4.7997\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0423 - mae: 3.0423\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7211 - mae: 4.7211\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0346 - mae: 2.0346\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1576 - mae: 4.1576\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.5082 - mae: 3.5082\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1100 - mae: 4.1100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4289 - mae: 2.4289\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.0008 - mae: 5.0008\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3409 - mae: 2.3409\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9120 - mae: 4.9120\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2572 - mae: 2.2572\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8301 - mae: 4.8301\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.1776 - mae: 2.1776\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.7543 - mae: 4.7543\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1020 - mae: 2.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f00f767ee0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more layers to the model and see if the prediction is improved\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50),\n",
    "    tf.keras.layers.Dense(25),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer= tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.918866]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0548 - mae: 11.0548\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.6048 - mae: 10.6048\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.1548 - mae: 10.1548\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.7048 - mae: 9.7048\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2548 - mae: 9.2548\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8048 - mae: 8.8048\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.3548 - mae: 8.3548\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9048 - mae: 7.9048\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4548 - mae: 7.4548\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0048 - mae: 7.0048\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6750 - mae: 6.6750\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6013 - mae: 6.6013\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6652 - mae: 6.6652\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7835 - mae: 6.7835\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8536 - mae: 6.8536\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8819 - mae: 6.8819\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8739 - mae: 6.8739\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8341 - mae: 6.8341\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7664 - mae: 6.7664\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6741 - mae: 6.6741\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.5602 - mae: 6.5602\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.4269 - mae: 6.4269\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2766 - mae: 6.2766\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.1110 - mae: 6.1110\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.9319 - mae: 5.9319\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.7406 - mae: 5.7406\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6637 - mae: 5.6637\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6047 - mae: 5.6047\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.5441 - mae: 5.5441\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.5875 - mae: 5.5875\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5963 - mae: 5.5963\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.5469 - mae: 5.5469\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4464 - mae: 5.4464\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.3007 - mae: 5.3007\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.1335 - mae: 5.1335\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.0600 - mae: 5.0600\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.9867 - mae: 4.9867\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9135 - mae: 4.9135\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8405 - mae: 4.8405\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.7975 - mae: 4.7975\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.7608 - mae: 4.7608\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6963 - mae: 4.6963\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6069 - mae: 4.6069\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4952 - mae: 4.4952\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4298 - mae: 4.4298\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3643 - mae: 4.3643\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.2979 - mae: 4.2979\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2308 - mae: 4.2308\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1630 - mae: 4.1630\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0946 - mae: 4.0946\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.0652 - mae: 4.0652\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9794 - mae: 3.9794\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8806 - mae: 3.8806\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8071 - mae: 3.8071\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7336 - mae: 3.7336\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6601 - mae: 3.6601\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5867 - mae: 3.5867\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5133 - mae: 3.5133\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.4709 - mae: 3.4709\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4081 - mae: 3.4081\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3176 - mae: 3.3176\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.2315 - mae: 3.2315\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1632 - mae: 3.1632\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.0943 - mae: 3.0943\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.0249 - mae: 3.0249\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9549 - mae: 2.9549\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.8846 - mae: 2.8846\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.8139 - mae: 2.8139\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7546 - mae: 2.7546\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6693 - mae: 2.6693\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5958 - mae: 2.5958\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5222 - mae: 2.5222\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4486 - mae: 2.4486\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3750 - mae: 2.3750\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3013 - mae: 2.3013\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2415 - mae: 2.2415\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1651 - mae: 2.1651\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0865 - mae: 2.0865\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0164 - mae: 2.0164\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9459 - mae: 1.9459\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8750 - mae: 1.8750\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8037 - mae: 1.8037\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7388 - mae: 1.7388\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6581 - mae: 1.6581\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5841 - mae: 1.5841\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5100 - mae: 1.5100\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4441 - mae: 1.4441\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3693 - mae: 1.3693\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2943 - mae: 1.2943\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2239 - mae: 1.2239\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1547 - mae: 1.1547\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0798 - mae: 1.0798\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0064 - mae: 1.0064\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9329 - mae: 0.9329\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8770 - mae: 0.8770\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7953 - mae: 0.7953\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7183 - mae: 0.7183\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6788 - mae: 0.6788\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5930 - mae: 0.5930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f00f846b20>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the optimizer \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "model.fit(tf.expand_dims(X,axis=-1),y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.401552]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 13.9468 - mae: 13.9468\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2859 - mae: 13.2859\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.6279 - mae: 12.6279\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.9702 - mae: 11.9702\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.3044 - mae: 11.3044\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.6244 - mae: 10.6244\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.9248 - mae: 9.9248\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.1949 - mae: 9.1949\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.4303 - mae: 8.4303\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6245 - mae: 7.6245\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7723 - mae: 6.7723\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.8960 - mae: 5.8960\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.9754 - mae: 4.9754\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.1323 - mae: 4.1323\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0312 - mae: 4.0312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9276 - mae: 3.9276\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9605 - mae: 3.9605\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9073 - mae: 3.9073\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9714 - mae: 3.9714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8999 - mae: 3.8999\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9595 - mae: 3.9595\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9079 - mae: 3.9079\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.9333 - mae: 3.9333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9160 - mae: 3.9160\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9096 - mae: 3.9096\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9309 - mae: 3.9309\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8864 - mae: 3.8864\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9391 - mae: 3.9391\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8681 - mae: 3.8681\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9381 - mae: 3.9381\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8763 - mae: 3.8763\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9117 - mae: 3.9117\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8854 - mae: 3.8854\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8910 - mae: 3.8910\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8996 - mae: 3.8996\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8641 - mae: 3.8641\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9080 - mae: 3.9080\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8374 - mae: 3.8374\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9154 - mae: 3.9154\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8459 - mae: 3.8459\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8888 - mae: 3.8888\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8594 - mae: 3.8594\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8678 - mae: 3.8678\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8695 - mae: 3.8695\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8407 - mae: 3.8407\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8782 - mae: 3.8782\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8134 - mae: 3.8134\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8870 - mae: 3.8870\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8165 - mae: 3.8165\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8678 - mae: 3.8678\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8318 - mae: 3.8318\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8433 - mae: 3.8433\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8405 - mae: 3.8405\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.8159 - mae: 3.8159\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8494 - mae: 3.8494\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7884 - mae: 3.7884\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8585 - mae: 3.8585\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7889 - mae: 3.7889\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8451 - mae: 3.8451\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8037 - mae: 3.8037\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8175 - mae: 3.8175\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8126 - mae: 3.8126\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7899 - mae: 3.7899\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8218 - mae: 3.8218\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7622 - mae: 3.7622\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8311 - mae: 3.8311\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7651 - mae: 3.7651\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8185 - mae: 3.8185\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7766 - mae: 3.7766\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7906 - mae: 3.7906\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7858 - mae: 3.7858\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7627 - mae: 3.7627\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7952 - mae: 3.7952\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7347 - mae: 3.7347\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8055 - mae: 3.8055\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7414 - mae: 3.7414\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7906 - mae: 3.7906\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7506 - mae: 3.7506\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7624 - mae: 3.7624\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7599 - mae: 3.7599\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7342 - mae: 3.7342\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7696 - mae: 3.7696\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7059 - mae: 3.7059\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7833 - mae: 3.7833\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7162 - mae: 3.7162\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7614 - mae: 3.7614\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7255 - mae: 3.7255\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7328 - mae: 3.7328\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7351 - mae: 3.7351\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7044 - mae: 3.7044\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6776 - mae: 3.6776\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7594 - mae: 3.7594\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6919 - mae: 3.6919\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7307 - mae: 3.7307\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7015 - mae: 3.7015\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7019 - mae: 3.7019\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7114 - mae: 3.7114\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6731 - mae: 3.6731\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7214 - mae: 3.7214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f00f816760>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see another change to improve our model\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# fit\n",
    "model.fit(tf.expand_dims(X,axis=-1),y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.941305]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see making some changes on our model can improve the result. Adding more layers or training our model on more epochs improved the result on the loss of our model. We can see that changing also the optimizer by using Adam improved a lot the model with a loss close to 0.6 and a prediction close to 27.\n",
    "\n",
    "However we can see in the examples that even if the loss is improved in some models, the result is still not close to 27. It means that maybe our model is overfitting on our training data. It is learning the patterns between X and y far too well. So when it sees a new x, it's just relating it back to what is knows and the error that it's producing during training is not a really valid representation.\n",
    "\n",
    "Now we have trained the model, we need to evaluate it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
